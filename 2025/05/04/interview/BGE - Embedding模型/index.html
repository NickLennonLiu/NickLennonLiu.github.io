<!doctype html><html lang=zh-CN><meta charset=UTF-8><meta content="width=device-width" name=viewport><meta content=#222 name=theme-color><meta content="Hexo 7.3.0" name=generator><link crossorigin href=https://cdnjs.cloudflare.com rel=preconnect><link href=/favicon/apple-touch-icon.png rel=apple-touch-icon sizes=180x180><link href=/favicon/web-app-manifest-512x512.png rel=icon sizes=32x32 type=image/png><link href=/favicon/web-app-manifest-192x192.png rel=icon sizes=16x16 type=image/png><link color=#222 href=/favicon/favicon.svg rel=mask-icon><meta content=dtILjtKPbqBNIxMl4PiZQihoHIODQU8NU2t2eulsvXI name=google-site-verification><meta content=codeva-7UaWTTz0pX name=baidu-site-verification><link href=/css/main.css rel=stylesheet><link integrity="sha256-dABdfBfUoC8vJUBOwGVdm8L9qlMWaHTIfXt+7GnZCIo=" crossorigin href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css rel=stylesheet><link integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin href=https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css rel=stylesheet><link integrity="sha256-zM8WXtG4eUn7dKKNMTuoWZub++VnSfaOpA/8PJfvTBo=" crossorigin href=https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.36/fancybox/fancybox.css rel=stylesheet><link href=https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/themes/blue/pace-theme-minimal.css rel=stylesheet><script integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin defer src=https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/pace.min.js></script><script class=next-config data-name=main type=application/json>{"hostname":"blog.river9.top","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.23.0","exturl":true,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"copycode":{"enable":true,"style":"flat"},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":true,"pangu":true,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"duration":200,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.json","localsearch":{"enable":true,"top_n_per_article":1,"unescape":false,"preload":false}}</script><script defer src=/js/config.js></script><meta content="BGE的目标是 做中文世界的通用embedding模型 。 通用，意味着 用一个模型，支持所有的embedding使用场景 ，包括但不限于：retrieval、re-rank、clustering、classification、pair-classification等任务。 BGE从两个方面来达成这个目标：  数据方面 ，兼顾 scale、 diversity、 quality这三个维度，这是通用" name=description><meta content=article property=og:type><meta content="BGE - Embedding模型" property=og:title><meta content=https://blog.river9.top/2025/05/04/interview/BGE%20-%20Embedding%E6%A8%A1%E5%9E%8B/index.html property=og:url><meta content="Junetheriver's Blog" property=og:site_name><meta content="BGE的目标是 做中文世界的通用embedding模型 。 通用，意味着 用一个模型，支持所有的embedding使用场景 ，包括但不限于：retrieval、re-rank、clustering、classification、pair-classification等任务。 BGE从两个方面来达成这个目标：  数据方面 ，兼顾 scale、 diversity、 quality这三个维度，这是通用" property=og:description><meta content=zh_CN property=og:locale><meta content="https://p3-volc-community-sign.byteimg.com/tos-cn-i-tlddhu82om/56d16c98e5744229bbb4958d25c63a0d~tplv-tlddhu82om-image.image?=&rk3s=8031ce6d&x-expires=1741658479&x-signature=rHhh8IH9U3SfnJe19ZbgRUb1Ogk%3D" property=og:image><meta content="https://p3-volc-community-sign.byteimg.com/tos-cn-i-tlddhu82om/a57df9b425834759a8a2c5080594af57~tplv-tlddhu82om-image.image?=&rk3s=8031ce6d&x-expires=1741658479&x-signature=rZlQupEz8Gx4hz5o1pOgcLGWOCU%3D" property=og:image><meta content="https://p3-volc-community-sign.byteimg.com/tos-cn-i-tlddhu82om/058f94d6c76f48cd84a95f7660a0749f~tplv-tlddhu82om-image.image?=&rk3s=8031ce6d&x-expires=1741658479&x-signature=tAmlFXZGxMksheawUql8JwPdbYc%3D" property=og:image><meta content="https://p3-volc-community-sign.byteimg.com/tos-cn-i-tlddhu82om/058f94d6c76f48cd84a95f7660a0749f~tplv-tlddhu82om-image.image?=&rk3s=8031ce6d&x-expires=1741658479&x-signature=tAmlFXZGxMksheawUql8JwPdbYc%3D" property=og:image><meta content="https://p3-volc-community-sign.byteimg.com/tos-cn-i-tlddhu82om/058f94d6c76f48cd84a95f7660a0749f~tplv-tlddhu82om-image.image?=&rk3s=8031ce6d&x-expires=1741658479&x-signature=tAmlFXZGxMksheawUql8JwPdbYc%3D" property=og:image><meta content="https://p3-volc-community-sign.byteimg.com/tos-cn-i-tlddhu82om/4fbf5360f27044c8bbff4fc265aa1861~tplv-tlddhu82om-image.image?=&rk3s=8031ce6d&x-expires=1741658479&x-signature=AjsQmBm65rL%2BXFh83GZATLdN6JI%3D" property=og:image><meta content=2025-05-03T19:04:40.305Z property=article:published_time><meta content=2025-05-04T03:07:01.881Z property=article:modified_time><meta content="River June" property=article:author><meta content=NLP property=article:tag><meta content=summary name=twitter:card><meta content="https://p3-volc-community-sign.byteimg.com/tos-cn-i-tlddhu82om/56d16c98e5744229bbb4958d25c63a0d~tplv-tlddhu82om-image.image?=&rk3s=8031ce6d&x-expires=1741658479&x-signature=rHhh8IH9U3SfnJe19ZbgRUb1Ogk%3D" name=twitter:image><link href=https://blog.river9.top/2025/05/04/interview/BGE%20-%20Embedding%E6%A8%A1%E5%9E%8B/ rel=canonical><script class=next-config data-name=page type=application/json>{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://blog.river9.top/2025/05/04/interview/BGE%20-%20Embedding%E6%A8%A1%E5%9E%8B/","path":"2025/05/04/interview/BGE - Embedding模型/","title":"BGE - Embedding模型"}</script><script class=next-config data-name=calendar type=application/json>""</script><title>BGE - Embedding模型 | Junetheriver's Blog</title><script alpha=0.6 defer size=600 src=https://cdnjs.cloudflare.com/ajax/libs/ribbon.js/1.0.2/ribbon.min.js zindex=-1></script><script integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin defer src=https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js></script><script integrity="sha256-vxLn1tSKWD4dqbMRyv940UYw4sXgMtYcK6reefzZrao=" crossorigin defer src=https://cdnjs.cloudflare.com/ajax/libs/next-theme-pjax/0.6.0/pjax.min.js></script><script integrity="sha256-hiUEBwFEpLF6DlB8sGXlKo4kPZ46Ui4qGpd0vrVkOm4=" crossorigin defer src=https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.36/fancybox/fancybox.umd.js></script><script integrity="sha256-mOFREFhqmHeQbXpK2lp4nA3qooVgACfh88fpJftLBbc=" crossorigin defer src=https://cdnjs.cloudflare.com/ajax/libs/lozad.js/1.16.0/lozad.min.js></script><script integrity="sha256-j+yj56cdEY2CwkVtGyz18fNybFGpMGJ8JxG3GSyO2+I=" crossorigin defer src=https://cdnjs.cloudflare.com/ajax/libs/pangu/4.0.7/pangu.min.js></script><script defer src=/js/utils.js></script><script defer src=/js/motion.js></script><script defer src=/js/sidebar.js></script><script defer src=/js/next-boot.js></script><script defer src=/js/pjax.js></script><script integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin defer src=https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js></script><script defer src=/js/third-party/search/local-search.js></script><script class=next-config data-name=pdf type=application/json>{"object_url":{"url":"https://cdnjs.cloudflare.com/ajax/libs/pdfobject/2.3.1/pdfobject.min.js","integrity":"sha256-jI72I8ZLVflVOisZIOaLvRew3tyvzeu6aZXFm7P7dEo="},"url":"/lib/pdf/web/viewer.html"}</script><script defer src=/js/third-party/tags/pdf.js></script><script class=next-config data-name=mermaid type=application/json>{"enable":true,"theme":{"light":"default","dark":"dark"},"js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mermaid/11.5.0/mermaid.min.js","integrity":"sha256-2obLuIPcceEhkE3G09G33hBdmE55ivVcZUlcKcGNHjU="}}</script><script defer src=/js/third-party/tags/mermaid.js></script><script defer src=/js/third-party/fancybox.js></script><script defer src=/js/third-party/pace.js></script><script defer src=/js/third-party/addtoany.js></script><script class=next-config data-name=enableMath type=application/json>false</script><link integrity="sha256-UF1fgpAiu3tPJN/uCqEUHNe7pnr+QR0SQDNfgglgtcM=" crossorigin href=https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css rel=stylesheet><script class=next-config data-name=katex type=application/json>{"copy_tex_js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/contrib/copy-tex.min.js","integrity":"sha256-Us54+rSGDSTvIhKKUs4kygE2ipA0RXpWWh0/zLqw3bs="}}</script><script defer src=/js/third-party/math/katex.js></script><script integrity="sha256-yvJQOINiH9fWemHn0vCA5lsHWJaHs6/ZmO+1Ft04SvM=" crossorigin defer src=https://cdnjs.cloudflare.com/ajax/libs/quicklink/2.3.0/quicklink.umd.js></script><script class=next-config data-name=quicklink type=application/json>{"enable":true,"home":true,"archive":true,"delay":true,"timeout":3000,"priority":true,"url":"https://blog.river9.top/2025/05/04/interview/BGE%20-%20Embedding%E6%A8%A1%E5%9E%8B/"}</script><script defer src=/js/third-party/quicklink.js></script><script class=next-config data-name=exif type=application/json>"{FocalLength}mm f/{ApertureValue} {ExposureTime}s"</script><script defer src=https://cdn.jsdelivr.net/npm/exifreader@4/dist/exif-reader.min.js></script><script defer src=/lib/exif.js></script><noscript><link href=/css/noscript.css rel=stylesheet></noscript><body class=use-motion itemscope itemtype=http://schema.org/WebPage><div class=headband></div><main class=main><div class=column><header class=header itemscope itemtype=http://schema.org/WPHeader><div class=site-brand-container><div class=site-nav-toggle><div aria-label=切换导航栏 class=toggle role=button><span class=toggle-line></span><span class=toggle-line></span><span class=toggle-line></span></div></div><div class=site-meta><a class=brand href=/ rel=start> <i class=logo-line></i> <p class=site-title>Junetheriver's Blog</p> <i class=logo-line></i> </a></div><div class=site-nav-right><div class="toggle popup-trigger" aria-label=搜索 role=button><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class=site-nav><ul class="main-menu menu"><li class="menu-item menu-item-home"><a href=/ rel=section><i class="fa fa-home fa-fw"></i>首页</a><li class="menu-item menu-item-about"><a href=/about/ rel=section><i class="fa fa-user fa-fw"></i>关于</a><li class="menu-item menu-item-tags"><a href=/tags/ rel=section><i class="fa fa-tags fa-fw"></i>标签<span class=badge>11</span></a><li class="menu-item menu-item-categories"><a href=/categories/ rel=section><i class="fa fa-th fa-fw"></i>分类<span class=badge>1</span></a><li class="menu-item menu-item-roadmap"><a href=/roadmap/ rel=section><i class="fa fa-road fa-fw"></i>Roadmap</a><li class="menu-item menu-item-search"><a class=popup-trigger role=button><i class="fa fa-search fa-fw"></i>搜索 </a></ul></nav><div class=search-pop-overlay><div class="popup search-popup"><div class=search-header><span class=search-icon> <i class="fa fa-search"></i> </span><div class=search-input-container><input autocapitalize=off autocomplete=off class=search-input maxlength=80 placeholder=搜索... spellcheck=false type=search></div><span class=popup-btn-close role=button> <i class="fa fa-times-circle"></i> </span></div><div class=search-result-container><div class=search-result-icon><i class="fa fa-spinner fa-pulse fa-5x"></i></div></div></div></div></header><aside class=sidebar><div class="sidebar-inner sidebar-nav-active sidebar-toc-active"><ul class=sidebar-nav><li class=sidebar-nav-toc>文章目录<li class=sidebar-nav-overview>站点概览</ul><div class=sidebar-panel-container><!--noindex--><div class="post-toc-wrap sidebar-panel"><div class="post-toc animated"><ol class=nav><li class="nav-item nav-level-2"><a class=nav-link href=#%E6%95%B0%E6%8D%AE><span class=nav-number>1.</span> <span class=nav-text> 数据</span></a><ol class=nav-child><li class="nav-item nav-level-3"><a class=nav-link href=#%E8%AE%AD%E7%BB%83%E6%96%B9%E9%9D%A2><span class=nav-number>1.1.</span> <span class=nav-text> 训练方面</span></a></ol><li class="nav-item nav-level-2"><a class=nav-link href=#%E8%AE%AD%E7%BB%83%E7%BB%86%E8%8A%82><span class=nav-number>2.</span> <span class=nav-text> 训练细节</span></a><ol class=nav-child><li class="nav-item nav-level-3"><a class=nav-link href=#pre-training%E9%98%B6%E6%AE%B5><span class=nav-number>2.1.</span> <span class=nav-text> pre-training阶段</span></a><li class="nav-item nav-level-3"><a class=nav-link href=#general-purpose-fine-tuning%E9%98%B6%E6%AE%B5><span class=nav-number>2.2.</span> <span class=nav-text> general-purpose fine-tuning阶段</span></a><li class="nav-item nav-level-3"><a class=nav-link href=#task-specific-fine-tuning%E9%98%B6%E6%AE%B5><span class=nav-number>2.3.</span> <span class=nav-text> task-specific fine-tuning阶段</span></a></ol><li class="nav-item nav-level-2"><a class=nav-link href=#bge%E7%9A%84%E6%95%88%E6%9E%9C%E5%A6%82%E4%BD%95><span class=nav-number>3.</span> <span class=nav-text> BGE的效果如何</span></a><li class="nav-item nav-level-2"><a class=nav-link href=#%E6%80%BB%E7%BB%93><span class=nav-number>4.</span> <span class=nav-text> 总结</span></a></ol></div></div><!--/noindex--><div class="site-overview-wrap sidebar-panel"><div class="site-author animated" itemprop=author itemscope itemtype=http://schema.org/Person><img alt="River June" class=site-author-image itemprop=image src=/favicon/cirno_pat.gif><p class=site-author-name itemprop=name>River June<div class=site-description itemprop=description>An Idiot to Anything</div></div><div class="links-of-author animated"><span class=links-of-author-item> <span data-url="aHR0cHM6Ly9naXRodWIuY29tL05pY2tMZW5ub25MaXU=" title="GitHub → https://github.com/NickLennonLiu" class=exturl><i class="fab fa-github fa-fw"></i>GitHub</span> </span><span class=links-of-author-item> <span data-url="bWFpbHRvOmp1bmV0aGVyaXZlckBnbWFpbC5jb20=" title="E-Mail → mailto:junetheriver@gmail.com" class=exturl><i class="fa fa-envelope fa-fw"></i>E-Mail</span> </span><span class=links-of-author-item> <span title="Bilibili → https://space.bilibili.com/800711" class=exturl data-url=aHR0cHM6Ly9zcGFjZS5iaWxpYmlsaS5jb20vODAwNzEx><i class="fa fa-television fa-fw"></i>Bilibili</span> </span></div></div></div></div><div class=pjax><div class="sidebar-inner sidebar-post-related"><div class=animated><div class=links-of-blogroll-title><i class="fa fa-signs-post fa-fw"></i> 相关文章</div><ul class=popular-posts><li class=popular-posts-item><a class=popular-posts-link href=/2025/05/04/interview/GRPO/ rel=bookmark> <time class=popular-posts-time>2025-05-04</time> <br> GRPO </a></ul></div></div></div></aside></div><div class="main-inner post posts-expand"><div class=post-block><article class=post-content itemscope itemtype=http://schema.org/Article lang=zh-CN><link href=https://blog.river9.top/2025/05/04/interview/BGE%20-%20Embedding%E6%A8%A1%E5%9E%8B/ itemprop=mainEntityOfPage><span hidden itemprop=author itemscope itemtype=http://schema.org/Person> <meta content=/favicon/cirno_pat.gif itemprop=image> <meta content="River June" itemprop=name> </span><span hidden itemprop=publisher itemscope itemtype=http://schema.org/Organization> <meta content="Junetheriver's Blog" itemprop=name> <meta content="An Idiot to Anything" itemprop=description> </span><span hidden itemprop=post itemscope itemtype=http://schema.org/CreativeWork> <meta content="BGE - Embedding模型 | Junetheriver's Blog" itemprop=name> <meta itemprop=description> </span><header class=post-header><h1 itemprop="name headline" class=post-title>BGE - Embedding模型</h1><div class=post-meta-container><div class=post-meta><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-calendar"></i> </span> <span class=post-meta-item-text>发表于</span> <time itemprop="dateCreated datePublished" title="创建时间：2025-05-04 03:04:40 / 修改时间：11:07:01" datetime=2025-05-04T03:04:40+08:00>2025-05-04</time> </span><span class=post-meta-break></span><span class=post-meta-item title=本文字数> <span class=post-meta-item-icon> <i class="far fa-file-word"></i> </span> <span class=post-meta-item-text>本文字数：</span> <span>1.5k</span> </span><span class=post-meta-item title=阅读时长> <span class=post-meta-item-icon> <i class="far fa-clock"></i> </span> <span class=post-meta-item-text>阅读时长 ≈</span> <span>6 分钟</span> </span></div></div></header><div class=post-body itemprop=articleBody><p>BGE的目标是 <strong>做中文世界的通用embedding模型</strong> 。<p>通用，意味着 <strong>用一个模型，支持所有的embedding使用场景</strong> ，包括但不限于：retrieval、re-rank、clustering、classification、pair-classification等任务。<p>BGE从两个方面来达成这个目标：<ul><li><strong>数据方面</strong> ，兼顾 <code>scale</code>、 <code>diversity</code>、 <code>quality</code>这三个维度，这是通用embedding模型能训练出来的<strong>前提</strong> ；<li><strong>训练策略方面</strong> ，论文使用3阶段训练策略，从 <code>pre-training</code> 到 <code>general-purpose fine-tuning</code> 再到 <code>task-specific fine-tuning</code>；前两个阶段是保证通用性的<strong>基石，</strong> 最后一个阶段则在<strong>保持通用</strong> 的基础上，进一步<strong>精进</strong> 下游任务的效果。</ul><h2 id=数据><a class=markdownIt-Anchor href=#数据></a> 数据</h2><p>在 <strong>训练数据</strong> 方面，论文构建了大量的text pair数据，论文称之 <code>C-MTP(Chinese Massive Text Pairs)</code>，数据量总计 <strong>100M</strong> ，涵盖多种任务，来自Wudao[3]等开源数据集，结合一些filter策略，同时达到scale、diversity、quality三个目标。<p>具体而言， <code>C-MTP</code>分成unlabeled和labeled两部分。<ol><li><strong>unlabeled</strong> 数据，源于open web content和public Chinese dataset。前者包括 <code>Wudao Corpora</code>、知乎、百科等数据，<strong>使用(title, passage)作为text pair</strong>；后者包括CSL、CMRC等公开数据集，这些数据集中pair结构天然存在，因此直接使用；同时，为了保证数据quality，使用Text2Vec-Chinese（预训练的中文embedding模型）[4]，过滤掉得分_低于0.43_的pair数据。最终数据量共计100M；<li><strong>labeled</strong> 数据，直接来自于下游任务的标注数据集，包括DuReader、mMARCO、NLI-Zh等，涵盖<strong>retrieval、ranking、similarity comparison</strong>等任务，数据量共计838K。</ol><p>在 <strong>测试数据</strong> 方面，论文构建了中文世界的benchmark，称之为 <code>C-MTEB(Chinese Massive Text Embedding Benchmark)</code>。<h3 id=训练方面><a class=markdownIt-Anchor href=#训练方面></a> 训练方面</h3><p><img data-src="https://p3-volc-community-sign.byteimg.com/tos-cn-i-tlddhu82om/56d16c98e5744229bbb4958d25c63a0d~tplv-tlddhu82om-image.image?=&rk3s=8031ce6d&x-expires=1741658479&x-signature=rHhh8IH9U3SfnJe19ZbgRUb1Ogk%3D" alt=picture.image><p>简要来说， <code>pre-training</code>阶段在 <code>Wudao Corpora</code>上进行，此阶段未在任何pair数据上训练，其目标是训练出更适合embedding任务的 <strong>pre-trained model</strong> ；<p><code>general-purpose fine-tuning</code>阶段在 <code>C-MTP(unlabeled)</code>上进行，该阶段在100M的text pairs上训练，可以视作一种 <strong>大规模的弱监督学习</strong> 过程，可初步学习出通用embedding model；<p>最后的 <code>task-specific fine-tuning</code>阶段，在 <code>C-MTP(labeled)</code>上进行，通过在少而精的下游任务labeled data上微调，在 <strong>保证通用性</strong> 的同时，强化模型在 <strong>具体任务</strong> 上的表现。<h2 id=训练细节><a class=markdownIt-Anchor href=#训练细节></a> 训练细节</h2><h3 id=pre-training阶段><a class=markdownIt-Anchor href=#pre-training阶段></a> pre-training阶段</h3><p>前文提到，这一阶段是为了学习出更适合embedding的pre-trained model。<p>论文采取了RetroMAE[5]的训练策略。其目标函数如下：<p><img data-src="https://p3-volc-community-sign.byteimg.com/tos-cn-i-tlddhu82om/a57df9b425834759a8a2c5080594af57~tplv-tlddhu82om-image.image?=&rk3s=8031ce6d&x-expires=1741658479&x-signature=rZlQupEz8Gx4hz5o1pOgcLGWOCU%3D" alt=picture.image><p>简单来说，就是先对text X进行随机Mask，然后进行encoding，再额外训练一个light-weight decoder（如单层transformer）进行重构。通过这一过程，强迫encoder学习到良好的embedding。<p>一个很自然的疑问是， <strong>这种方法比Bert要好吗？</strong><p><img data-src="https://p3-volc-community-sign.byteimg.com/tos-cn-i-tlddhu82om/058f94d6c76f48cd84a95f7660a0749f~tplv-tlddhu82om-image.image?=&rk3s=8031ce6d&x-expires=1741658479&x-signature=tAmlFXZGxMksheawUql8JwPdbYc%3D" alt=picture.image><p>作者对此进行了实验。其中 <code>BGE-i w.o. pre-train</code>模型直接使用了Chinese-RoBERTa[6]，与本文的 <code>BGE-i</code>模型对比，可以发现 <strong>整体表现其实差不多</strong> ，只是在 <strong>retrieval任务</strong> 上有较明显的提升。<blockquote><p>retroMAE的提出也正是为了增强retrieval任务的表现。</blockquote><h3 id=general-purpose-fine-tuning阶段><a class=markdownIt-Anchor href=#general-purpose-fine-tuning阶段></a> general-purpose fine-tuning阶段</h3><p>这一阶段的核心技术是对比学习，重点是：<ol><li>采用in-batch negative sample方法；<li>使用大batch_size（论文使用的size为19200）。</ol><p>这一阶段主打一个简单粗暴 – <strong>只要batch够大，在batch内就足以找到hard negative sample</strong> 。<p><img data-src="https://p3-volc-community-sign.byteimg.com/tos-cn-i-tlddhu82om/058f94d6c76f48cd84a95f7660a0749f~tplv-tlddhu82om-image.image?=&rk3s=8031ce6d&x-expires=1741658479&x-signature=tAmlFXZGxMksheawUql8JwPdbYc%3D" alt=picture.image><p>论文实验表明， <code>BGE-i</code>（仅经过general-purpose fine-tuning）的整体表现就 <strong>已经可以超过</strong> <code>OpenAI-Ada-002</code>和 <code>M3E（large）</code>了，细看一番，其中 <strong>优势最大的是retrieval任务</strong> ，这与其训练数据（ <code>C-MTP-unlabel</code>）中包含大量web content中的（title，passage）有很大的关系。<blockquote><p>着重优化retrieval任务的表现，应该是BGE团队的刻意为之；毕竟retrieval是embedding model最常见的使用场景。</blockquote><h3 id=task-specific-fine-tuning阶段><a class=markdownIt-Anchor href=#task-specific-fine-tuning阶段></a> task-specific fine-tuning阶段</h3><p>这一阶段的难点在于： <strong>在任务间存在差异的情况下，如何更好地multi-task learning。</strong><p>论文采取了两个关键技术：<ol><li>instruction-based fine-tuning[7]。核心思路是将衡量 <code>sim（x1，x2）</code>，转化为衡量 <code>sim（instruction+x1，instruction+x2）</code>，这个instruction就是一段text prompt，用以说明domain、task等内容。例如在retrieval任务中，query侧加入的instruction为 <code>为这个句子生成表示以用于检索相关文章：</code>；<li><strong>hard negative sampling</strong> 。在训练过程中，采取ANN-style sampling strategy[8]，从该任务的corpus中<strong>全局性</strong> 地采样出一个<strong>embedding表征最接近的hard negative sample</strong> 。</ol><p><img data-src="https://p3-volc-community-sign.byteimg.com/tos-cn-i-tlddhu82om/058f94d6c76f48cd84a95f7660a0749f~tplv-tlddhu82om-image.image?=&rk3s=8031ce6d&x-expires=1741658479&x-signature=tAmlFXZGxMksheawUql8JwPdbYc%3D" alt=picture.image><p>论文实验表明， <code>BGE-f</code>（经过task-specific fine-tuning之后的最终模型），在retrieval、STS、pair-classification、re-rank上 <strong>明显好于</strong> <code>BGE-i</code>模型，其他任务也 <strong>几乎没有效果损失</strong> 。<p><strong>这充分说明了论文所采取的fine-tuning技术的有效性</strong> 。<p>可以认为，这也是BGE团队做出的fine-tuning示范。<h2 id=bge的效果如何><a class=markdownIt-Anchor href=#bge的效果如何></a> BGE的效果如何</h2><p>BGE所采取的模型结构类似于BERT，使用其最后一层中 <code>CLS token</code>的hidden state作为embedding。<p>BGE模型有3个不同大小的版本，其中small版参数量为 <strong>24M</strong> 、base版参数量为 <strong>102M</strong> 、large版参数量为 <strong>326M</strong> 。<p>论文在 <code>C-MTEB</code>上与众多embedding模型进行了对比，结果如下。<p><img data-src="https://p3-volc-community-sign.byteimg.com/tos-cn-i-tlddhu82om/4fbf5360f27044c8bbff4fc265aa1861~tplv-tlddhu82om-image.image?=&rk3s=8031ce6d&x-expires=1741658479&x-signature=AjsQmBm65rL%2BXFh83GZATLdN6JI%3D" alt=picture.image><p>可以看到， <strong>BGE-base和BGE-large基本是一骑绝尘</strong> ，几乎在每一个任务上的效果都明显更好， <strong>即使是BGE-small，也几乎能达到SOTA的效果</strong> 。<h2 id=总结><a class=markdownIt-Anchor href=#总结></a> 总结</h2><p>本文对BGE的论文进行了简要解读，指出其在数据侧、训练侧所采取的方法论，同时对其三阶段训练过程的技术细节进行了介绍。<p>一个很明显的感受： <strong>BGE是一个产品</strong> ，它做到的是集各家之所长（数据、训练技术等），产品的诞生便是它的创新之处。从论文实验来看，在中文的各项任务上，就算是 <code>small-size BGE</code>，也可以战胜 <code>OpenAI-Ada-002</code>，而且BGE是开源的 – 这意味着每个人都可以对它再次进行fine-tuning，以进一步提升效果。这的确是中文开发者的福音。</div><footer class=post-footer><div class=post-copyright><ul><li class=post-copyright-author><strong>本文作者： </strong>River June<li class=post-copyright-link><strong>本文链接：</strong> <a title="BGE - Embedding模型" href=https://blog.river9.top/2025/05/04/interview/BGE%20-%20Embedding%E6%A8%A1%E5%9E%8B/>https://blog.river9.top/2025/05/04/interview/BGE - Embedding模型/</a><li class=post-copyright-license><strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <span data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC8=" class=exturl><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</span> 许可协议。转载请注明出处！</ul></div><div class=post-tags><a href=/tags/NLP/ rel=tag><i class="fa fa-tag"></i> NLP</a></div><div class="social-like a2a_kit a2a_kit_size_32 a2a_default_style"><a class=a2a_dd href=https://www.addtoany.com/share rel=noopener target=_blank></a><a class=a2a_button_facebook></a><a class=a2a_button_twitter></a><a class=a2a_button_telegram></a><a class=a2a_button_wechat></a></div><div class=post-nav><div class=post-nav-item><a href=/2025/05/04/interview/DeepSeek/ rel=prev title=DeepSeek> <i class="fa fa-angle-left"></i> DeepSeek </a></div><div class=post-nav-item><a title="MCP Server" href=/2025/05/04/interview/MCP%20Server/ rel=next> MCP Server <i class="fa fa-angle-right"></i> </a></div></div></footer></article></div><div class=comments id=disqus_thread><noscript>Please enable JavaScript to view the comments powered by Disqus.</noscript></div></div></main><footer class=footer><div class=footer-inner><div class=copyright>© <span itemprop=copyrightYear>2025</span><span class=with-love> <i class="fa fa-9"></i> </span><span class=author itemprop=copyrightHolder>River June</span></div><div class=wordcount><span class=post-meta-item> <span class=post-meta-item-icon> <i class="fa fa-chart-line"></i> </span> <span title=站点总字数>13k</span> </span><span class=post-meta-item> <span class=post-meta-item-icon> <i class="fa fa-coffee"></i> </span> <span title=站点阅读时长>48 分钟</span> </span></div><div class=powered-by>由 <span class=exturl data-url=aHR0cHM6Ly9oZXhvLmlv>Hexo</span> & <span data-url="aHR0cHM6Ly90aGVtZS1uZXh0LmpzLm9yZw==" class=exturl>NexT.Gemini</span> 强力驱动</div></div></footer><div class="toggle sidebar-toggle" role=button><span class=toggle-line></span><span class=toggle-line></span><span class=toggle-line></span></div><div class=sidebar-dimmer></div><div aria-label=返回顶部 class=back-to-top role=button><i class="fa fa-arrow-up fa-lg"></i><span>0%</span></div><div class=reading-progress-bar></div><span aria-label="在 GitHub 上关注我" class="exturl github-corner" data-url="aHR0cHM6Ly9naXRodWIuY29tL05pY2tMZW5ub25MaXU=" title="在 GitHub 上关注我"><svg viewbox="0 0 250 250" aria-hidden=true height=80 width=80><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" style="transform-origin: 130px 106px;" class=octo-arm fill=currentColor></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" class=octo-body fill=currentColor></path></svg></span><noscript><div class=noscript-warning>Theme NexT works best with JavaScript enabled</div></noscript><script class=next-config data-name=disqus type=application/json>{"enable":true,"shortname":"blog-river9","count":false,"i18n":{"disqus":"disqus"}}</script><script defer src=/js/third-party/comments/disqus.js></script>