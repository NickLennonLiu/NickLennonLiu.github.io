<!doctype html><html lang=zh-CN><meta charset=UTF-8><meta content="width=device-width" name=viewport><meta content=#222 name=theme-color><meta content="Hexo 7.3.0" name=generator><link crossorigin href=https://cdnjs.cloudflare.com rel=preconnect><link href=/favicon/apple-touch-icon.png rel=apple-touch-icon sizes=180x180><link href=/favicon/web-app-manifest-512x512.png rel=icon sizes=32x32 type=image/png><link href=/favicon/web-app-manifest-192x192.png rel=icon sizes=16x16 type=image/png><link color=#222 href=/favicon/favicon.svg rel=mask-icon><meta content=dtILjtKPbqBNIxMl4PiZQihoHIODQU8NU2t2eulsvXI name=google-site-verification><meta content=codeva-7UaWTTz0pX name=baidu-site-verification><link href=/css/main.css rel=stylesheet><link integrity="sha256-dABdfBfUoC8vJUBOwGVdm8L9qlMWaHTIfXt+7GnZCIo=" crossorigin href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css rel=stylesheet><link integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin href=https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css rel=stylesheet><link integrity="sha256-zM8WXtG4eUn7dKKNMTuoWZub++VnSfaOpA/8PJfvTBo=" crossorigin href=https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.36/fancybox/fancybox.css rel=stylesheet><link href=https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/themes/blue/pace-theme-minimal.css rel=stylesheet><script integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin defer src=https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/pace.min.js></script><script class=next-config data-name=main type=application/json>{"hostname":"blog.river9.top","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.23.0","exturl":true,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"copycode":{"enable":true,"style":"flat"},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":true,"pangu":true,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"duration":200,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.json","localsearch":{"enable":true,"top_n_per_article":1,"unescape":false,"preload":false}}</script><script defer src=/js/config.js></script><meta content="An Idiot to Anything" name=description><meta content=website property=og:type><meta content="Junetheriver's Blog" property=og:title><meta content=https://blog.river9.top/page/2/index.html property=og:url><meta content="Junetheriver's Blog" property=og:site_name><meta content="An Idiot to Anything" property=og:description><meta content=zh_CN property=og:locale><meta content="River June" property=article:author><meta content=summary name=twitter:card><link href=https://blog.river9.top/page/2/ rel=canonical><script class=next-config data-name=page type=application/json>{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-CN","comments":"","permalink":"","path":"page/2/index.html","title":""}</script><script class=next-config data-name=calendar type=application/json>""</script><title>Junetheriver's Blog</title><script alpha=0.6 defer size=600 src=https://cdnjs.cloudflare.com/ajax/libs/ribbon.js/1.0.2/ribbon.min.js zindex=-1></script><script integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin defer src=https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js></script><script integrity="sha256-vxLn1tSKWD4dqbMRyv940UYw4sXgMtYcK6reefzZrao=" crossorigin defer src=https://cdnjs.cloudflare.com/ajax/libs/next-theme-pjax/0.6.0/pjax.min.js></script><script integrity="sha256-hiUEBwFEpLF6DlB8sGXlKo4kPZ46Ui4qGpd0vrVkOm4=" crossorigin defer src=https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.36/fancybox/fancybox.umd.js></script><script integrity="sha256-mOFREFhqmHeQbXpK2lp4nA3qooVgACfh88fpJftLBbc=" crossorigin defer src=https://cdnjs.cloudflare.com/ajax/libs/lozad.js/1.16.0/lozad.min.js></script><script integrity="sha256-j+yj56cdEY2CwkVtGyz18fNybFGpMGJ8JxG3GSyO2+I=" crossorigin defer src=https://cdnjs.cloudflare.com/ajax/libs/pangu/4.0.7/pangu.min.js></script><script defer src=/js/utils.js></script><script defer src=/js/motion.js></script><script defer src=/js/sidebar.js></script><script defer src=/js/next-boot.js></script><script defer src=/js/pjax.js></script><script integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin defer src=https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js></script><script defer src=/js/third-party/search/local-search.js></script><script class=next-config data-name=pdf type=application/json>{"object_url":{"url":"https://cdnjs.cloudflare.com/ajax/libs/pdfobject/2.3.1/pdfobject.min.js","integrity":"sha256-jI72I8ZLVflVOisZIOaLvRew3tyvzeu6aZXFm7P7dEo="},"url":"/lib/pdf/web/viewer.html"}</script><script defer src=/js/third-party/tags/pdf.js></script><script class=next-config data-name=mermaid type=application/json>{"enable":true,"theme":{"light":"default","dark":"dark"},"js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mermaid/11.5.0/mermaid.min.js","integrity":"sha256-2obLuIPcceEhkE3G09G33hBdmE55ivVcZUlcKcGNHjU="}}</script><script defer src=/js/third-party/tags/mermaid.js></script><script defer src=/js/third-party/fancybox.js></script><script defer src=/js/third-party/pace.js></script><script defer src=/js/third-party/addtoany.js></script><script class=next-config data-name=enableMath type=application/json>false</script><link integrity="sha256-UF1fgpAiu3tPJN/uCqEUHNe7pnr+QR0SQDNfgglgtcM=" crossorigin href=https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css rel=stylesheet><script class=next-config data-name=katex type=application/json>{"copy_tex_js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/contrib/copy-tex.min.js","integrity":"sha256-Us54+rSGDSTvIhKKUs4kygE2ipA0RXpWWh0/zLqw3bs="}}</script><script defer src=/js/third-party/math/katex.js></script><script integrity="sha256-yvJQOINiH9fWemHn0vCA5lsHWJaHs6/ZmO+1Ft04SvM=" crossorigin defer src=https://cdnjs.cloudflare.com/ajax/libs/quicklink/2.3.0/quicklink.umd.js></script><script class=next-config data-name=quicklink type=application/json>{"enable":true,"home":true,"archive":true,"delay":true,"timeout":3000,"priority":true,"url":"https://blog.river9.top/page/2/"}</script><script defer src=/js/third-party/quicklink.js></script><script class=next-config data-name=exif type=application/json>"{FocalLength}mm f/{ApertureValue} {ExposureTime}s"</script><script defer src=https://cdn.jsdelivr.net/npm/exifreader@4/dist/exif-reader.min.js></script><script defer src=/lib/exif.js></script><noscript><link href=/css/noscript.css rel=stylesheet></noscript><body class=use-motion itemscope itemtype=http://schema.org/WebPage><div class=headband></div><main class=main><div class=column><header class=header itemscope itemtype=http://schema.org/WPHeader><div class=site-brand-container><div class=site-nav-toggle><div aria-label=切换导航栏 class=toggle role=button><span class=toggle-line></span><span class=toggle-line></span><span class=toggle-line></span></div></div><div class=site-meta><a class=brand href=/ rel=start> <i class=logo-line></i> <h1 class=site-title>Junetheriver's Blog</h1> <i class=logo-line></i> </a></div><div class=site-nav-right><div class="toggle popup-trigger" aria-label=搜索 role=button><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class=site-nav><ul class="main-menu menu"><li class="menu-item menu-item-home"><a href=/ rel=section><i class="fa fa-home fa-fw"></i>首页</a><li class="menu-item menu-item-about"><a href=/about/ rel=section><i class="fa fa-user fa-fw"></i>关于</a><li class="menu-item menu-item-tags"><a href=/tags/ rel=section><i class="fa fa-tags fa-fw"></i>标签<span class=badge>11</span></a><li class="menu-item menu-item-categories"><a href=/categories/ rel=section><i class="fa fa-th fa-fw"></i>分类<span class=badge>1</span></a><li class="menu-item menu-item-roadmap"><a href=/roadmap/ rel=section><i class="fa fa-road fa-fw"></i>Roadmap</a><li class="menu-item menu-item-search"><a class=popup-trigger role=button><i class="fa fa-search fa-fw"></i>搜索 </a></ul></nav><div class=search-pop-overlay><div class="popup search-popup"><div class=search-header><span class=search-icon> <i class="fa fa-search"></i> </span><div class=search-input-container><input autocapitalize=off autocomplete=off class=search-input maxlength=80 placeholder=搜索... spellcheck=false type=search></div><span class=popup-btn-close role=button> <i class="fa fa-times-circle"></i> </span></div><div class=search-result-container><div class=search-result-icon><i class="fa fa-spinner fa-pulse fa-5x"></i></div></div></div></div></header><aside class=sidebar><div class="sidebar-inner sidebar-overview-active"><ul class=sidebar-nav><li class=sidebar-nav-toc>文章目录<li class=sidebar-nav-overview>站点概览</ul><div class=sidebar-panel-container><!--noindex--><div class="post-toc-wrap sidebar-panel"></div><!--/noindex--><div class="site-overview-wrap sidebar-panel"><div class="site-author animated" itemprop=author itemscope itemtype=http://schema.org/Person><img alt="River June" class=site-author-image itemprop=image src=/favicon/cirno_pat.gif><p class=site-author-name itemprop=name>River June<div class=site-description itemprop=description>An Idiot to Anything</div></div><div class="links-of-author animated"><span class=links-of-author-item> <span data-url="aHR0cHM6Ly9naXRodWIuY29tL05pY2tMZW5ub25MaXU=" title="GitHub → https://github.com/NickLennonLiu" class=exturl><i class="fab fa-github fa-fw"></i>GitHub</span> </span><span class=links-of-author-item> <span data-url="bWFpbHRvOmp1bmV0aGVyaXZlckBnbWFpbC5jb20=" title="E-Mail → mailto:junetheriver@gmail.com" class=exturl><i class="fa fa-envelope fa-fw"></i>E-Mail</span> </span><span class=links-of-author-item> <span title="Bilibili → https://space.bilibili.com/800711" class=exturl data-url=aHR0cHM6Ly9zcGFjZS5iaWxpYmlsaS5jb20vODAwNzEx><i class="fa fa-television fa-fw"></i>Bilibili</span> </span></div></div></div></div><div class=pjax></div></aside></div><div class="main-inner index posts-expand"><div class=post-block><article class=post-content itemscope itemtype=http://schema.org/Article><link href=https://blog.river9.top/2025/05/04/interview/MCP%20Server/ itemprop=mainEntityOfPage><span hidden itemprop=author itemscope itemtype=http://schema.org/Person> <meta content=/favicon/cirno_pat.gif itemprop=image> <meta content="River June" itemprop=name> </span><span hidden itemprop=publisher itemscope itemtype=http://schema.org/Organization> <meta content="Junetheriver's Blog" itemprop=name> <meta content="An Idiot to Anything" itemprop=description> </span><span hidden itemprop=post itemscope itemtype=http://schema.org/CreativeWork> <meta content="undefined | Junetheriver's Blog" itemprop=name> <meta itemprop=description> </span><header class=post-header><h2 itemprop="name headline" class=post-title><a class=post-title-link href=/2025/05/04/interview/MCP%20Server/ itemprop=url>MCP Server</a></h2><div class=post-meta-container><div class=post-meta><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-calendar"></i> </span> <span class=post-meta-item-text>发表于</span> <time itemprop="dateCreated datePublished" title="创建时间：2025-05-04 03:04:40 / 修改时间：11:07:29" datetime=2025-05-04T03:04:40+08:00>2025-05-04</time> </span><span class=post-meta-break></span><span class=post-meta-item title=本文字数> <span class=post-meta-item-icon> <i class="far fa-file-word"></i> </span> <span class=post-meta-item-text>本文字数：</span> <span>463</span> </span><span class=post-meta-item title=阅读时长> <span class=post-meta-item-icon> <i class="far fa-clock"></i> </span> <span class=post-meta-item-text>阅读时长 ≈</span> <span>2 分钟</span> </span></div></div></header><div class=post-body itemprop=articleBody><p>![[Pasted image 20250430171745.png]]<p>以下是 MCP 的基本工作流程：<ul><li><p>初始化连接：客户端向服务器发送连接请求，建立通信通道。</p><li><p>发送请求：客户端根据需求构建请求消息，并发送给服务器。</p><li><p>处理请求：服务器接收到请求后，解析请求内容，执行相应的操作（如查询数据库、读取文件等）。</p><li><p>返回结果：服务器将处理结果封装成响应消息，发送回客户端。</p><li><p>断开连接：任务完成后，客户端可以主动关闭连接或等待服务器超时关闭。<br> ![[Pasted image 20250430172002.png]]<br> MCP 遵循客户端-服务器架构（client-server），其中包含以下几个核心概念：</p><li><p>MCP 主机（MCP Hosts）：发起请求的 LLM 应用程序（例如 <span class=exturl data-url=aHR0cHM6Ly96aGlkYS56aGlodS5jb20vc2VhcmNoP2NvbnRlbnRfaWQ9MjU0NDg4MTUzJmNvbnRlbnRfdHlwZT1BcnRpY2xlJm1hdGNoX29yZGVyPTEmcT1DbGF1ZGUrRGVza3RvcCZ6aGlkYV9zb3VyY2U9ZW50aXR5>Claude Desktop<i class="fa fa-external-link-alt"></i></span>、IDE 或 AI 工具）。</p><li><p>MCP 客户端（MCP Clients）：在主机程序内部，与 MCP server 保持 1:1 的连接。</p><li><p>MCP 服务器（MCP Servers）：为 MCP client 提供上下文、工具和 prompt 信息。</p><li><p>本地资源（Local Resources）：本地计算机中可供 MCP server 安全访问的资源（例如文件、数据库）。</p><li><p>远程资源（Remote Resources）：MCP server 可以连接到的远程资源（例如通过 API）。<br> ![[Pasted image 20250430171755.png]]</p></ul><h3 id=通信机制><a class=markdownIt-Anchor href=#通信机制></a> <strong>通信机制</strong></h3><p>MCP 协议支持两种主要的通信机制：基于标准输入输出的本地通信和基于<span data-url="aHR0cHM6Ly96aGlkYS56aGlodS5jb20vc2VhcmNoP2NvbnRlbnRfaWQ9MjU0NDg4MTUzJmNvbnRlbnRfdHlwZT1BcnRpY2xlJm1hdGNoX29yZGVyPTEmcT1TU0UmemhpZGFfc291cmNlPWVudGl0eQ==" class=exturl>SSE<i class="fa fa-external-link-alt"></i></span>（<span class=exturl data-url=aHR0cHM6Ly9saW5rLnpoaWh1LmNvbS8/dGFyZ2V0PWh0dHBzJTNBLy9lbi53aWtpcGVkaWEub3JnL3dpa2kvU2VydmVyLXNlbnRfZXZlbnRz>Server-Sent Events<i class="fa fa-external-link-alt"></i></span>）的远程通信。<p>这两种机制都使用 <span data-url="aHR0cHM6Ly9saW5rLnpoaWh1LmNvbS8/dGFyZ2V0PWh0dHBzJTNBLy93d3cuanNvbnJwYy5vcmcvc3BlY2lmaWNhdGlvbg==" class=exturl>JSON-RPC 2.0<i class="fa fa-external-link-alt"></i></span> 格式进行消息传输，确保了通信的标准化和可扩展性。<ul><li>本地通信**：**通过 stdio 传输数据，适用于在同一台机器上运行的客户端和服务器之间的通信。<li>远程通信**：**利用 SSE 与 HTTP 结合，实现跨网络的实时数据传输，适用于需要访问远程资源或分布式部署的场景。</ul></div><footer class=post-footer><div class=post-eof></div></footer></article></div><div class=post-block><article class=post-content itemscope itemtype=http://schema.org/Article><link href=https://blog.river9.top/2025/05/04/interview/BGE%20-%20Embedding%E6%A8%A1%E5%9E%8B/ itemprop=mainEntityOfPage><span hidden itemprop=author itemscope itemtype=http://schema.org/Person> <meta content=/favicon/cirno_pat.gif itemprop=image> <meta content="River June" itemprop=name> </span><span hidden itemprop=publisher itemscope itemtype=http://schema.org/Organization> <meta content="Junetheriver's Blog" itemprop=name> <meta content="An Idiot to Anything" itemprop=description> </span><span hidden itemprop=post itemscope itemtype=http://schema.org/CreativeWork> <meta content="undefined | Junetheriver's Blog" itemprop=name> <meta itemprop=description> </span><header class=post-header><h2 itemprop="name headline" class=post-title><a class=post-title-link href=/2025/05/04/interview/BGE%20-%20Embedding%E6%A8%A1%E5%9E%8B/ itemprop=url>BGE - Embedding模型</a></h2><div class=post-meta-container><div class=post-meta><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-calendar"></i> </span> <span class=post-meta-item-text>发表于</span> <time itemprop="dateCreated datePublished" title="创建时间：2025-05-04 03:04:40 / 修改时间：11:07:01" datetime=2025-05-04T03:04:40+08:00>2025-05-04</time> </span><span class=post-meta-break></span><span class=post-meta-item title=本文字数> <span class=post-meta-item-icon> <i class="far fa-file-word"></i> </span> <span class=post-meta-item-text>本文字数：</span> <span>1.5k</span> </span><span class=post-meta-item title=阅读时长> <span class=post-meta-item-icon> <i class="far fa-clock"></i> </span> <span class=post-meta-item-text>阅读时长 ≈</span> <span>6 分钟</span> </span></div></div></header><div class=post-body itemprop=articleBody><p>BGE的目标是 <strong>做中文世界的通用embedding模型</strong> 。<p>通用，意味着 <strong>用一个模型，支持所有的embedding使用场景</strong> ，包括但不限于：retrieval、re-rank、clustering、classification、pair-classification等任务。<p>BGE从两个方面来达成这个目标：<ul><li><strong>数据方面</strong> ，兼顾 <code>scale</code>、 <code>diversity</code>、 <code>quality</code>这三个维度，这是通用embedding模型能训练出来的<strong>前提</strong> ；<li><strong>训练策略方面</strong> ，论文使用3阶段训练策略，从 <code>pre-training</code> 到 <code>general-purpose fine-tuning</code> 再到 <code>task-specific fine-tuning</code>；前两个阶段是保证通用性的<strong>基石，</strong> 最后一个阶段则在<strong>保持通用</strong> 的基础上，进一步<strong>精进</strong> 下游任务的效果。</ul><h2 id=数据><a class=markdownIt-Anchor href=#数据></a> 数据</h2><p>在 <strong>训练数据</strong> 方面，论文构建了大量的text pair数据，论文称之 <code>C-MTP(Chinese Massive Text Pairs)</code>，数据量总计 <strong>100M</strong> ，涵盖多种任务，来自Wudao[3]等开源数据集，结合一些filter策略，同时达到scale、diversity、quality三个目标。<p>具体而言， <code>C-MTP</code>分成unlabeled和labeled两部分。<ol><li><strong>unlabeled</strong> 数据，源于open web content和public Chinese dataset。前者包括 <code>Wudao Corpora</code>、知乎、百科等数据，<strong>使用(title, passage)作为text pair</strong>；后者包括CSL、CMRC等公开数据集，这些数据集中pair结构天然存在，因此直接使用；同时，为了保证数据quality，使用Text2Vec-Chinese（预训练的中文embedding模型）[4]，过滤掉得分_低于0.43_的pair数据。最终数据量共计100M；<li><strong>labeled</strong> 数据，直接来自于下游任务的标注数据集，包括DuReader、mMARCO、NLI-Zh等，涵盖<strong>retrieval、ranking、similarity comparison</strong>等任务，数据量共计838K。</ol><p>在 <strong>测试数据</strong> 方面，论文构建了中文世界的benchmark，称之为 <code>C-MTEB(Chinese Massive Text Embedding Benchmark)</code>。<h3 id=训练方面><a class=markdownIt-Anchor href=#训练方面></a> 训练方面</h3><p><img data-src="https://p3-volc-community-sign.byteimg.com/tos-cn-i-tlddhu82om/56d16c98e5744229bbb4958d25c63a0d~tplv-tlddhu82om-image.image?=&rk3s=8031ce6d&x-expires=1741658479&x-signature=rHhh8IH9U3SfnJe19ZbgRUb1Ogk%3D" alt=picture.image><p>简要来说， <code>pre-training</code>阶段在 <code>Wudao Corpora</code>上进行，此阶段未在任何pair数据上训练，其目标是训练出更适合embedding任务的 <strong>pre-trained model</strong> ；<p><code>general-purpose fine-tuning</code>阶段在 <code>C-MTP(unlabeled)</code>上进行，该阶段在100M的text pairs上训练，可以视作一种 <strong>大规模的弱监督学习</strong> 过程，可初步学习出通用embedding model；<p>最后的 <code>task-specific fine-tuning</code>阶段，在 <code>C-MTP(labeled)</code>上进行，通过在少而精的下游任务labeled data上微调，在 <strong>保证通用性</strong> 的同时，强化模型在 <strong>具体任务</strong> 上的表现。<h2 id=训练细节><a class=markdownIt-Anchor href=#训练细节></a> 训练细节</h2><h3 id=pre-training阶段><a class=markdownIt-Anchor href=#pre-training阶段></a> pre-training阶段</h3><p>前文提到，这一阶段是为了学习出更适合embedding的pre-trained model。<p>论文采取了RetroMAE[5]的训练策略。其目标函数如下：<p><img data-src="https://p3-volc-community-sign.byteimg.com/tos-cn-i-tlddhu82om/a57df9b425834759a8a2c5080594af57~tplv-tlddhu82om-image.image?=&rk3s=8031ce6d&x-expires=1741658479&x-signature=rZlQupEz8Gx4hz5o1pOgcLGWOCU%3D" alt=picture.image><p>简单来说，就是先对text X进行随机Mask，然后进行encoding，再额外训练一个light-weight decoder（如单层transformer）进行重构。通过这一过程，强迫encoder学习到良好的embedding。<p>一个很自然的疑问是， <strong>这种方法比Bert要好吗？</strong><p><img data-src="https://p3-volc-community-sign.byteimg.com/tos-cn-i-tlddhu82om/058f94d6c76f48cd84a95f7660a0749f~tplv-tlddhu82om-image.image?=&rk3s=8031ce6d&x-expires=1741658479&x-signature=tAmlFXZGxMksheawUql8JwPdbYc%3D" alt=picture.image><p>作者对此进行了实验。其中 <code>BGE-i w.o. pre-train</code>模型直接使用了Chinese-RoBERTa[6]，与本文的 <code>BGE-i</code>模型对比，可以发现 <strong>整体表现其实差不多</strong> ，只是在 <strong>retrieval任务</strong> 上有较明显的提升。<blockquote><p>retroMAE的提出也正是为了增强retrieval任务的表现。</blockquote><h3 id=general-purpose-fine-tuning阶段><a class=markdownIt-Anchor href=#general-purpose-fine-tuning阶段></a> general-purpose fine-tuning阶段</h3><p>这一阶段的核心技术是对比学习，重点是：<ol><li>采用in-batch negative sample方法；<li>使用大batch_size（论文使用的size为19200）。</ol><p>这一阶段主打一个简单粗暴 – <strong>只要batch够大，在batch内就足以找到hard negative sample</strong> 。<p><img data-src="https://p3-volc-community-sign.byteimg.com/tos-cn-i-tlddhu82om/058f94d6c76f48cd84a95f7660a0749f~tplv-tlddhu82om-image.image?=&rk3s=8031ce6d&x-expires=1741658479&x-signature=tAmlFXZGxMksheawUql8JwPdbYc%3D" alt=picture.image><p>论文实验表明， <code>BGE-i</code>（仅经过general-purpose fine-tuning）的整体表现就 <strong>已经可以超过</strong> <code>OpenAI-Ada-002</code>和 <code>M3E（large）</code>了，细看一番，其中 <strong>优势最大的是retrieval任务</strong> ，这与其训练数据（ <code>C-MTP-unlabel</code>）中包含大量web content中的（title，passage）有很大的关系。<blockquote><p>着重优化retrieval任务的表现，应该是BGE团队的刻意为之；毕竟retrieval是embedding model最常见的使用场景。</blockquote><h3 id=task-specific-fine-tuning阶段><a class=markdownIt-Anchor href=#task-specific-fine-tuning阶段></a> task-specific fine-tuning阶段</h3><p>这一阶段的难点在于： <strong>在任务间存在差异的情况下，如何更好地multi-task learning。</strong><p>论文采取了两个关键技术：<ol><li>instruction-based fine-tuning[7]。核心思路是将衡量 <code>sim（x1，x2）</code>，转化为衡量 <code>sim（instruction+x1，instruction+x2）</code>，这个instruction就是一段text prompt，用以说明domain、task等内容。例如在retrieval任务中，query侧加入的instruction为 <code>为这个句子生成表示以用于检索相关文章：</code>；<li><strong>hard negative sampling</strong> 。在训练过程中，采取ANN-style sampling strategy[8]，从该任务的corpus中<strong>全局性</strong> 地采样出一个<strong>embedding表征最接近的hard negative sample</strong> 。</ol><p><img data-src="https://p3-volc-community-sign.byteimg.com/tos-cn-i-tlddhu82om/058f94d6c76f48cd84a95f7660a0749f~tplv-tlddhu82om-image.image?=&rk3s=8031ce6d&x-expires=1741658479&x-signature=tAmlFXZGxMksheawUql8JwPdbYc%3D" alt=picture.image><p>论文实验表明， <code>BGE-f</code>（经过task-specific fine-tuning之后的最终模型），在retrieval、STS、pair-classification、re-rank上 <strong>明显好于</strong> <code>BGE-i</code>模型，其他任务也 <strong>几乎没有效果损失</strong> 。<p><strong>这充分说明了论文所采取的fine-tuning技术的有效性</strong> 。<p>可以认为，这也是BGE团队做出的fine-tuning示范。<h2 id=bge的效果如何><a class=markdownIt-Anchor href=#bge的效果如何></a> BGE的效果如何</h2><p>BGE所采取的模型结构类似于BERT，使用其最后一层中 <code>CLS token</code>的hidden state作为embedding。<p>BGE模型有3个不同大小的版本，其中small版参数量为 <strong>24M</strong> 、base版参数量为 <strong>102M</strong> 、large版参数量为 <strong>326M</strong> 。<p>论文在 <code>C-MTEB</code>上与众多embedding模型进行了对比，结果如下。<p><img data-src="https://p3-volc-community-sign.byteimg.com/tos-cn-i-tlddhu82om/4fbf5360f27044c8bbff4fc265aa1861~tplv-tlddhu82om-image.image?=&rk3s=8031ce6d&x-expires=1741658479&x-signature=AjsQmBm65rL%2BXFh83GZATLdN6JI%3D" alt=picture.image><p>可以看到， <strong>BGE-base和BGE-large基本是一骑绝尘</strong> ，几乎在每一个任务上的效果都明显更好， <strong>即使是BGE-small，也几乎能达到SOTA的效果</strong> 。<h2 id=总结><a class=markdownIt-Anchor href=#总结></a> 总结</h2><p>本文对BGE的论文进行了简要解读，指出其在数据侧、训练侧所采取的方法论，同时对其三阶段训练过程的技术细节进行了介绍。<p>一个很明显的感受： <strong>BGE是一个产品</strong> ，它做到的是集各家之所长（数据、训练技术等），产品的诞生便是它的创新之处。从论文实验来看，在中文的各项任务上，就算是 <code>small-size BGE</code>，也可以战胜 <code>OpenAI-Ada-002</code>，而且BGE是开源的 – 这意味着每个人都可以对它再次进行fine-tuning，以进一步提升效果。这的确是中文开发者的福音。</div><footer class=post-footer><div class=post-eof></div></footer></article></div><div class=post-block><article class=post-content itemscope itemtype=http://schema.org/Article><link href=https://blog.river9.top/2025/05/04/interview/DeepSeek/ itemprop=mainEntityOfPage><span hidden itemprop=author itemscope itemtype=http://schema.org/Person> <meta content=/favicon/cirno_pat.gif itemprop=image> <meta content="River June" itemprop=name> </span><span hidden itemprop=publisher itemscope itemtype=http://schema.org/Organization> <meta content="Junetheriver's Blog" itemprop=name> <meta content="An Idiot to Anything" itemprop=description> </span><span hidden itemprop=post itemscope itemtype=http://schema.org/CreativeWork> <meta content="undefined | Junetheriver's Blog" itemprop=name> <meta itemprop=description> </span><header class=post-header><h2 itemprop="name headline" class=post-title><a class=post-title-link href=/2025/05/04/interview/DeepSeek/ itemprop=url>DeepSeek</a></h2><div class=post-meta-container><div class=post-meta><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-calendar"></i> </span> <span class=post-meta-item-text>发表于</span> <time itemprop="dateCreated datePublished" title="创建时间：2025-05-04 03:04:40 / 修改时间：11:07:10" datetime=2025-05-04T03:04:40+08:00>2025-05-04</time> </span><span class=post-meta-break></span><span class=post-meta-item title=本文字数> <span class=post-meta-item-icon> <i class="far fa-file-word"></i> </span> <span class=post-meta-item-text>本文字数：</span> <span>2.2k</span> </span><span class=post-meta-item title=阅读时长> <span class=post-meta-item-icon> <i class="far fa-clock"></i> </span> <span class=post-meta-item-text>阅读时长 ≈</span> <span>8 分钟</span> </span></div></div></header><div class=post-body itemprop=articleBody><h2 id=资料><a class=markdownIt-Anchor href=#资料></a> 资料</h2><p><span data-url="aHR0cHM6Ly93d3cuemhpaHUuY29tL3RhcmRpcy96bS9hcnQvMTk4Njg5MzUxNTI=" class=exturl>https://www.zhihu.com/tardis/zm/art/19868935152<i class="fa fa-external-link-alt"></i></span><br> <span data-url="aHR0cHM6Ly9naXRodWIuY29tL2RlZXBzZWVrLWFpL0RlZXBTZWVrLVIxL2Jsb2IvbWFpbi9EZWVwU2Vla19SMS5wZGY=" class=exturl>https://github.com/deepseek-ai/DeepSeek-R1/blob/main/DeepSeek_R1.pdf<i class="fa fa-external-link-alt"></i></span><br> [[DeepSeek_R1.pdf]]<p>![[Pasted image 20250220155728.png]]<p><strong>研究问题</strong>：如何通过[[强化学习]]（RL）有效提升大型语言模型（LLM）的推理能力？<br> <strong>问题背景：</strong><ul><li>之前的研究大多依赖于大量的 SFT 数据，但获取高质量的 SFT 数据成本高昂。<li>OpenAI 的 o1 系列模型通过增加思维链（Chain-of-Thought, CoT）推理过程的长度来提升推理能力，但如何有效进行测试时（test-time）扩展仍是开放问题。<li>一些研究尝试使用基于过程的奖励模型（PRM）、强化学习和搜索算法（MCTS）来解决推理问题，但没有达到 OpenAI 的 o1 系列模型的通用推理性能水平。<br> <strong>论文动机：</strong> 探索是否可以通过纯强化学习来让 LLM 自主发展推理能力，而无需依赖 SFT 数据。</ul><h2 id=r1的多阶段训练策略><a class=markdownIt-Anchor href=#r1的多阶段训练策略></a> R1的多阶段训练策略</h2><h3 id=阶段1-有监督微调sft冷启动><a class=markdownIt-Anchor href=#阶段1-有监督微调sft冷启动></a> 阶段1： 有监督微调SFT（冷启动）</h3><p>使用少量高质量的 CoT 数据进行冷启动，预热模型。<br> DeepSeek-R1 使用冷启动数据的主要目的是为了解决 DeepSeek-R1-Zero 在训练早期出现的训练不稳定问题。相比于直接在基础模型上进行 RL，使用少量的 SFT 数据进行冷启动，可以让模型更快地进入稳定训练阶段：<ul><li><strong>可读性</strong>：冷启动数据使用更易于理解的格式，输出内容更适合人类阅读，避免了 DeepSeek-R1-Zero 输出的语言混合、格式混乱等问题。<li><strong>潜在性能</strong>：通过精心设计冷启动数据的模式，可以引导模型产生更好的推理能力。<li><strong>稳定训练</strong>：使用 SFT 数据作为起始点，可以避免 RL 训练早期阶段的不稳定问题。</ul><p>为了获取这些数据，deepseek 探索了几种策略：利用长思维回答作为 few-shot 示例，直接提示模型生成包含反思和验证步骤的详细答案，以及收集 DeepSeek-R1-Zero 的输出并通过人工标注者进行细化。最终收集了数千条冷启动数据，用以微调 DeepSeek-V3-Base 作为 RL 训练的起点。DeepSeek-R1 创建的冷启动数据采用了一种可读模式，明确将输出格式定义为：|special_token|&lt;reasoning_process>|special_token|&lt;summary_>。<h3 id=阶段2rl基于规则奖励><a class=markdownIt-Anchor href=#阶段2rl基于规则奖励></a> 阶段2：RL（基于规则奖励）</h3><p>(R1-Zero)规则奖励：<ul><li><strong>准确率奖励</strong>：准确率奖励模型评估响应是否正确。例如，在具有确定性结果的数学问题中，模型需要以指定的格式（box）提供最终答案，从而能够通过基于规则的验证来可靠地确认正确性。同样，对于 LeetCode 问题，可以使用编译器根据预定义的测试用例生成反馈。<li><strong>格式奖励</strong>: 除了准确性奖励模型，还采用了一种格式奖励模型，要求模型将其思考过程放在 ‘’ 和 ‘’ 标签之间。</ul><p>在R1的训练时，引入<strong>语言一致性奖励</strong>，该奖励根据思维链（CoT）中目标语言单词的比例来计算，以减少推理过程中的语言混合问题。<p>尽管消融实验表明，<strong>语言一致性奖励</strong>会导致模型性能略有下降，但它更符合人类的偏好，提高了内容的可读性。最终，通过将推理任务的准确性与语言一致性奖励直接相加，形成了综合的奖励函数。随后，对微调后的模型进行了强化学习（RL）训练，直至其在推理任务上达到收敛。<h3 id=阶段3拒绝采样和两轮sftcot数据60w通用数据20w><a class=markdownIt-Anchor href=#阶段3拒绝采样和两轮sftcot数据60w通用数据20w></a> 阶段3：拒绝采样和两轮SFT（CoT数据60w+通用数据20w）</h3><p>使用上一阶段的 RL 模型进行拒绝采样，生成高质量的推理和非推理数据，并用这些数据对模型进行微调。侧重点是提升模型的综合能力，使其在写作、事实问答等多种任务上表现良好。<p>当 RL 训练接近收敛时，使用中间的 checkpoint 来采样监督微调（SFT）数据。与初期主要关注推理能力的冷启动数据不同，这一阶段加入了其他领域的数据，旨在增强模型在写作、角色扮演以及其他通用任务上的表现。具体的数据生成和模型微调步骤如下：<ul><li>对于推理数据，构建推理 prompt，并从上述 RL 训练的 checkpoint 中进行拒绝采样，以生成推理轨迹。在之前的阶段，仅使用了基于规则的奖励来评估数据。然而，在这个阶段，通过添加其他数据来丰富数据集，其中部分数据使用了<strong>生成奖励模型</strong>，通过将真实值和模型预测输入 DeepSeek-V3 进行判断。同时，为了提升数据质量，过滤掉混合语言、长段落和代码块的思维链。对于每个提示，采样多个响应，并仅保留正确的响应。最终，收集了大约<strong>60万</strong>个与推理相关的训练样本。<li>对于非推理数据，如写作、问答、翻译等任务，使用 DeepSeek-V3 SFT 数据集的一部分。对于简单的 query，如“你好”，不使用思维链作为回答。经过筛选和整理，最终收集了大约<strong>20万</strong>个与推理无关的训练样本。</ul><p>最终，使用大约<strong>80万</strong>个样本（60w推理+20w通用）对 DeepSeek-v3-Base 模型进行了两轮的 SFT。<h3 id=阶段4全场景强化学习规则奖励奖励模型><a class=markdownIt-Anchor href=#阶段4全场景强化学习规则奖励奖励模型></a> 阶段4：全场景强化学习（规则奖励+奖励模型）</h3><p>在上一阶段 SFT 模型的基础上进行 RL 训练，侧重点是使模型在所有场景下都能表现良好，包括推理任务和非推理任务，并且保证模型的安全性和无害性。<h2 id=r1-zero的aha-moment><a class=markdownIt-Anchor href=#r1-zero的aha-moment></a> R1-Zero的Aha Moment</h2><p>在大规模强化学习中，模型的「思考过程」会不断与最终的<strong>正确率奖励</strong>相互作用。当模型最初得出的答案并未得到较高奖励时，它会在后续的推理中「<strong>回头反省</strong>」，尝试补充或修正先前的思路，从而获得更高的奖励。随着强化学习的迭代，这种「<strong>主动回溯、推翻先前想法并重新推理</strong>」的行为逐渐巩固，便在输出中表现为所谓的「<strong>aha moment</strong>」。本质上，这是 RL 为模型「留出了」足够的思考和试错空间，当模型自行发现更优思路时，就会出现类似人类「恍然大悟」的瞬间。<h2 id=一些问题><a class=markdownIt-Anchor href=#一些问题></a> 一些问题</h2><h3 id=为什么在蒸馏到小模型时直接用-rl-在小模型上训练不如先做大模型再蒸馏><a class=markdownIt-Anchor href=#为什么在蒸馏到小模型时直接用-rl-在小模型上训练不如先做大模型再蒸馏></a> 为什么在蒸馏到小模型时，直接用 RL 在小模型上训练不如先做大模型再蒸馏？</h3><p>大模型在 RL 阶段可能出现许多高阶推理模式。而小模型因为容量和表示能力有限，很难在无监督或纯 RL 情境下学到相似水平的推理模式。<p>蒸馏可将「大模型的推理轨迹」直接转移给小模型，小模型只需要模仿大模型相对完备的推理流程，可以在较小训练/推理开销下取得远胜于自身独立强化学习的效果。<p>在蒸馏模型的实现中，仅采用了 SFT 阶段，而未包含 RL 阶段，尽管 RL 的加入能显著提升模型性能。按照 deepseek 的说法，本工作的核心目的在于展示<strong>蒸馏技术的有效性</strong>，而将 RL 阶段的深入探索留给更广泛的研究社群去完成。<h2 id=为什么-prm-和-mcts-没有成功><a class=markdownIt-Anchor href=#为什么-prm-和-mcts-没有成功></a> 为什么 PRM 和 MCTS 没有成功？</h2><p>论文中提到，基于过程奖励模型（PRM）和蒙特卡洛树搜索（MCTS）并不适合 LLM 的推理。<h3 id=prm-的挑战><a class=markdownIt-Anchor href=#prm-的挑战></a> PRM 的挑战</h3><ul><li>难以定义通用的、细粒度的推理步骤。<li>难以准确判断中间步骤的正确性，且自动标注方法效果不佳，人工标注又难以扩展。<li>模型化的 PRM 容易导致<strong>奖励黑客</strong>（Agent 利用奖励函数或环境中的漏洞来获取高奖励，而并未真正学习到预期行为。）行为，并且会增加额外的训练成本。</ul><h3 id=mcts-的挑战><a class=markdownIt-Anchor href=#mcts-的挑战></a> MCTS 的挑战</h3><ul><li>LLM 的 token 生成搜索空间巨大，远远超出棋类游戏，容易陷入局部最优解。<li>价值模型的训练非常困难，导致难以迭代提升。</ul><h2 id=结论><a class=markdownIt-Anchor href=#结论></a> 结论</h2><ul><li>第一，将更强大的模型蒸馏到较小模型中能产生优异的结果，而依赖大规模强化学习的小模型则需消耗巨大的计算资源，且可能仍无法达到蒸馏所能达到的性能水平。<li>第二，尽管蒸馏策略既经济又高效，但若要突破智能的界限，可能仍需依赖更强大的基础模型以及大规模强化学习。</ul></div><footer class=post-footer><div class=post-eof></div></footer></article></div><div class=post-block><article class=post-content itemscope itemtype=http://schema.org/Article><link href=https://blog.river9.top/2025/05/01/hello/ itemprop=mainEntityOfPage><span hidden itemprop=author itemscope itemtype=http://schema.org/Person> <meta content=/favicon/cirno_pat.gif itemprop=image> <meta content="River June" itemprop=name> </span><span hidden itemprop=publisher itemscope itemtype=http://schema.org/Organization> <meta content="Junetheriver's Blog" itemprop=name> <meta content="An Idiot to Anything" itemprop=description> </span><span hidden itemprop=post itemscope itemtype=http://schema.org/CreativeWork> <meta content="undefined | Junetheriver's Blog" itemprop=name> <meta itemprop=description> </span><header class=post-header><h2 itemprop="name headline" class=post-title><a class=post-title-link href=/2025/05/01/hello/ itemprop=url>Hello</a></h2><div class=post-meta-container><div class=post-meta><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-calendar"></i> </span> <span class=post-meta-item-text>发表于</span> <time itemprop="dateCreated datePublished" title="创建时间：2025-05-01 11:19:29" datetime=2025-05-01T11:19:29+08:00>2025-05-01</time> </span><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-calendar-check"></i> </span> <span class=post-meta-item-text>更新于</span> <time title="修改时间：2025-05-04 10:34:19" datetime=2025-05-04T10:34:19+08:00 itemprop=dateModified>2025-05-04</time> </span><span class=post-meta-break></span><span class=post-meta-item title=本文字数> <span class=post-meta-item-icon> <i class="far fa-file-word"></i> </span> <span class=post-meta-item-text>本文字数：</span> <span>6</span> </span><span class=post-meta-item title=阅读时长> <span class=post-meta-item-icon> <i class="far fa-clock"></i> </span> <span class=post-meta-item-text>阅读时长 ≈</span> <span>1 分钟</span> </span></div></div></header><div class=post-body itemprop=articleBody><h1 id=hello><a class=markdownIt-Anchor href=#hello></a> Hello</h1><p>This is the default note.</div><footer class=post-footer><div class=post-eof></div></footer></article></div><nav class=pagination><a class="extend prev" aria-label=上一页 href=/ rel=prev title=上一页><i class="fa fa-angle-left"></i></a><a class=page-number href=/>1</a><span class="page-number current">2</span></nav></div></main><footer class=footer><div class=footer-inner><div class=copyright>© <span itemprop=copyrightYear>2025</span><span class=with-love> <i class="fa fa-9"></i> </span><span class=author itemprop=copyrightHolder>River June</span></div><div class=wordcount><span class=post-meta-item> <span class=post-meta-item-icon> <i class="fa fa-chart-line"></i> </span> <span title=站点总字数>13k</span> </span><span class=post-meta-item> <span class=post-meta-item-icon> <i class="fa fa-coffee"></i> </span> <span title=站点阅读时长>48 分钟</span> </span></div><div class=powered-by>由 <span class=exturl data-url=aHR0cHM6Ly9oZXhvLmlv>Hexo</span> & <span data-url="aHR0cHM6Ly90aGVtZS1uZXh0LmpzLm9yZw==" class=exturl>NexT.Gemini</span> 强力驱动</div></div></footer><div class="toggle sidebar-toggle" role=button><span class=toggle-line></span><span class=toggle-line></span><span class=toggle-line></span></div><div class=sidebar-dimmer></div><div aria-label=返回顶部 class=back-to-top role=button><i class="fa fa-arrow-up fa-lg"></i><span>0%</span></div><div class=reading-progress-bar></div><span aria-label="在 GitHub 上关注我" class="exturl github-corner" data-url="aHR0cHM6Ly9naXRodWIuY29tL05pY2tMZW5ub25MaXU=" title="在 GitHub 上关注我"><svg viewbox="0 0 250 250" aria-hidden=true height=80 width=80><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" style="transform-origin: 130px 106px;" class=octo-arm fill=currentColor></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" class=octo-body fill=currentColor></path></svg></span><noscript><div class=noscript-warning>Theme NexT works best with JavaScript enabled</div></noscript><script class=next-config data-name=disqus type=application/json>{"enable":true,"shortname":"blog-river9","count":false,"i18n":{"disqus":"disqus"}}</script><script defer src=/js/third-party/comments/disqus.js></script>