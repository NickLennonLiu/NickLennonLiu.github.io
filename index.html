<!doctype html><html lang=zh-CN><meta charset=UTF-8><meta content="width=device-width" name=viewport><meta content=#222 name=theme-color><meta content="Hexo 7.3.0" name=generator><link crossorigin href=https://cdnjs.cloudflare.com rel=preconnect><link href=/favicon/apple-touch-icon.png rel=apple-touch-icon sizes=180x180><link href=/favicon/web-app-manifest-512x512.png rel=icon sizes=32x32 type=image/png><link href=/favicon/web-app-manifest-192x192.png rel=icon sizes=16x16 type=image/png><link color=#222 href=/favicon/favicon.svg rel=mask-icon><meta content=dtILjtKPbqBNIxMl4PiZQihoHIODQU8NU2t2eulsvXI name=google-site-verification><meta content=codeva-7UaWTTz0pX name=baidu-site-verification><link href=/css/main.css rel=stylesheet><link integrity="sha256-dABdfBfUoC8vJUBOwGVdm8L9qlMWaHTIfXt+7GnZCIo=" crossorigin href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css rel=stylesheet><link integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin href=https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css rel=stylesheet><link integrity="sha256-zM8WXtG4eUn7dKKNMTuoWZub++VnSfaOpA/8PJfvTBo=" crossorigin href=https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.36/fancybox/fancybox.css rel=stylesheet><link href=https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/themes/blue/pace-theme-minimal.css rel=stylesheet><script integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin defer src=https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/pace.min.js></script><script class=next-config data-name=main type=application/json>{"hostname":"blog.river9.top","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.23.0","exturl":true,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"copycode":{"enable":true,"style":"flat"},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":true,"pangu":true,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"duration":200,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.json","localsearch":{"enable":true,"top_n_per_article":1,"unescape":false,"preload":false}}</script><script defer src=/js/config.js></script><meta content="An Idiot to Anything" name=description><meta content=website property=og:type><meta content="Junetheriver's Blog" property=og:title><meta content=https://blog.river9.top/index.html property=og:url><meta content="Junetheriver's Blog" property=og:site_name><meta content="An Idiot to Anything" property=og:description><meta content=zh_CN property=og:locale><meta content="River June" property=article:author><meta content=summary name=twitter:card><link href=https://blog.river9.top/ rel=canonical><script class=next-config data-name=page type=application/json>{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-CN","comments":"","permalink":"","path":"index.html","title":""}</script><script class=next-config data-name=calendar type=application/json>""</script><title>Junetheriver's Blog</title><script alpha=0.6 defer size=600 src=https://cdnjs.cloudflare.com/ajax/libs/ribbon.js/1.0.2/ribbon.min.js zindex=-1></script><script integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin defer src=https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js></script><script integrity="sha256-vxLn1tSKWD4dqbMRyv940UYw4sXgMtYcK6reefzZrao=" crossorigin defer src=https://cdnjs.cloudflare.com/ajax/libs/next-theme-pjax/0.6.0/pjax.min.js></script><script integrity="sha256-hiUEBwFEpLF6DlB8sGXlKo4kPZ46Ui4qGpd0vrVkOm4=" crossorigin defer src=https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.36/fancybox/fancybox.umd.js></script><script integrity="sha256-mOFREFhqmHeQbXpK2lp4nA3qooVgACfh88fpJftLBbc=" crossorigin defer src=https://cdnjs.cloudflare.com/ajax/libs/lozad.js/1.16.0/lozad.min.js></script><script integrity="sha256-j+yj56cdEY2CwkVtGyz18fNybFGpMGJ8JxG3GSyO2+I=" crossorigin defer src=https://cdnjs.cloudflare.com/ajax/libs/pangu/4.0.7/pangu.min.js></script><script defer src=/js/utils.js></script><script defer src=/js/motion.js></script><script defer src=/js/sidebar.js></script><script defer src=/js/next-boot.js></script><script defer src=/js/pjax.js></script><script integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin defer src=https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js></script><script defer src=/js/third-party/search/local-search.js></script><script class=next-config data-name=pdf type=application/json>{"object_url":{"url":"https://cdnjs.cloudflare.com/ajax/libs/pdfobject/2.3.1/pdfobject.min.js","integrity":"sha256-jI72I8ZLVflVOisZIOaLvRew3tyvzeu6aZXFm7P7dEo="},"url":"/lib/pdf/web/viewer.html"}</script><script defer src=/js/third-party/tags/pdf.js></script><script class=next-config data-name=mermaid type=application/json>{"enable":true,"theme":{"light":"default","dark":"dark"},"js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mermaid/11.5.0/mermaid.min.js","integrity":"sha256-2obLuIPcceEhkE3G09G33hBdmE55ivVcZUlcKcGNHjU="}}</script><script defer src=/js/third-party/tags/mermaid.js></script><script defer src=/js/third-party/fancybox.js></script><script defer src=/js/third-party/pace.js></script><script defer src=/js/third-party/addtoany.js></script><script class=next-config data-name=enableMath type=application/json>false</script><link integrity="sha256-UF1fgpAiu3tPJN/uCqEUHNe7pnr+QR0SQDNfgglgtcM=" crossorigin href=https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css rel=stylesheet><script class=next-config data-name=katex type=application/json>{"copy_tex_js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/contrib/copy-tex.min.js","integrity":"sha256-Us54+rSGDSTvIhKKUs4kygE2ipA0RXpWWh0/zLqw3bs="}}</script><script defer src=/js/third-party/math/katex.js></script><script integrity="sha256-yvJQOINiH9fWemHn0vCA5lsHWJaHs6/ZmO+1Ft04SvM=" crossorigin defer src=https://cdnjs.cloudflare.com/ajax/libs/quicklink/2.3.0/quicklink.umd.js></script><script class=next-config data-name=quicklink type=application/json>{"enable":true,"home":true,"archive":true,"delay":true,"timeout":3000,"priority":true,"url":"https://blog.river9.top/"}</script><script defer src=/js/third-party/quicklink.js></script><script class=next-config data-name=exif type=application/json>"{FocalLength}mm f/{ApertureValue} {ExposureTime}s"</script><script defer src=https://cdn.jsdelivr.net/npm/exifreader@4/dist/exif-reader.min.js></script><script defer src=/lib/exif.js></script><noscript><link href=/css/noscript.css rel=stylesheet></noscript><body class=use-motion itemscope itemtype=http://schema.org/WebPage><div class=headband></div><main class=main><div class=column><header class=header itemscope itemtype=http://schema.org/WPHeader><div class=site-brand-container><div class=site-nav-toggle><div aria-label=切换导航栏 class=toggle role=button><span class=toggle-line></span><span class=toggle-line></span><span class=toggle-line></span></div></div><div class=site-meta><a class=brand href=/ rel=start> <i class=logo-line></i> <h1 class=site-title>Junetheriver's Blog</h1> <i class=logo-line></i> </a></div><div class=site-nav-right><div class="toggle popup-trigger" aria-label=搜索 role=button><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class=site-nav><ul class="main-menu menu"><li class="menu-item menu-item-home"><a href=/ rel=section><i class="fa fa-home fa-fw"></i>首页</a><li class="menu-item menu-item-about"><a href=/about/ rel=section><i class="fa fa-user fa-fw"></i>关于</a><li class="menu-item menu-item-tags"><a href=/tags/ rel=section><i class="fa fa-tags fa-fw"></i>标签<span class=badge>11</span></a><li class="menu-item menu-item-categories"><a href=/categories/ rel=section><i class="fa fa-th fa-fw"></i>分类<span class=badge>1</span></a><li class="menu-item menu-item-roadmap"><a href=/roadmap/ rel=section><i class="fa fa-road fa-fw"></i>Roadmap</a><li class="menu-item menu-item-search"><a class=popup-trigger role=button><i class="fa fa-search fa-fw"></i>搜索 </a></ul></nav><div class=search-pop-overlay><div class="popup search-popup"><div class=search-header><span class=search-icon> <i class="fa fa-search"></i> </span><div class=search-input-container><input autocapitalize=off autocomplete=off class=search-input maxlength=80 placeholder=搜索... spellcheck=false type=search></div><span class=popup-btn-close role=button> <i class="fa fa-times-circle"></i> </span></div><div class=search-result-container><div class=search-result-icon><i class="fa fa-spinner fa-pulse fa-5x"></i></div></div></div></div></header><aside class=sidebar><div class="sidebar-inner sidebar-overview-active"><ul class=sidebar-nav><li class=sidebar-nav-toc>文章目录<li class=sidebar-nav-overview>站点概览</ul><div class=sidebar-panel-container><!--noindex--><div class="post-toc-wrap sidebar-panel"></div><!--/noindex--><div class="site-overview-wrap sidebar-panel"><div class="site-author animated" itemprop=author itemscope itemtype=http://schema.org/Person><img alt="River June" class=site-author-image itemprop=image src=/favicon/cirno_pat.gif><p class=site-author-name itemprop=name>River June<div class=site-description itemprop=description>An Idiot to Anything</div></div><div class="links-of-author animated"><span class=links-of-author-item> <span data-url="aHR0cHM6Ly9naXRodWIuY29tL05pY2tMZW5ub25MaXU=" title="GitHub → https://github.com/NickLennonLiu" class=exturl><i class="fab fa-github fa-fw"></i>GitHub</span> </span><span class=links-of-author-item> <span data-url="bWFpbHRvOmp1bmV0aGVyaXZlckBnbWFpbC5jb20=" title="E-Mail → mailto:junetheriver@gmail.com" class=exturl><i class="fa fa-envelope fa-fw"></i>E-Mail</span> </span><span class=links-of-author-item> <span title="Bilibili → https://space.bilibili.com/800711" class=exturl data-url=aHR0cHM6Ly9zcGFjZS5iaWxpYmlsaS5jb20vODAwNzEx><i class="fa fa-television fa-fw"></i>Bilibili</span> </span></div></div></div></div><div class=pjax></div></aside></div><div class="main-inner index posts-expand"><div class=post-block><article class=post-content itemscope itemtype=http://schema.org/Article><link href=https://blog.river9.top/2025/05/04/interview/NLP/ itemprop=mainEntityOfPage><span hidden itemprop=author itemscope itemtype=http://schema.org/Person> <meta content=/favicon/cirno_pat.gif itemprop=image> <meta content="River June" itemprop=name> </span><span hidden itemprop=publisher itemscope itemtype=http://schema.org/Organization> <meta content="Junetheriver's Blog" itemprop=name> <meta content="An Idiot to Anything" itemprop=description> </span><span hidden itemprop=post itemscope itemtype=http://schema.org/CreativeWork> <meta content="undefined | Junetheriver's Blog" itemprop=name> <meta itemprop=description> </span><header class=post-header><h2 itemprop="name headline" class=post-title><a class=post-title-link href=/2025/05/04/interview/NLP/ itemprop=url>NLP</a></h2><div class=post-meta-container><div class=post-meta><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-calendar"></i> </span> <span class=post-meta-item-text>发表于</span> <time itemprop="dateCreated datePublished" title="创建时间：2025-05-04 11:04:40" datetime=2025-05-04T11:04:40+08:00>2025-05-04</time> </span><span class=post-meta-break></span><span class=post-meta-item title=本文字数> <span class=post-meta-item-icon> <i class="far fa-file-word"></i> </span> <span class=post-meta-item-text>本文字数：</span> <span>216</span> </span><span class=post-meta-item title=阅读时长> <span class=post-meta-item-icon> <i class="far fa-clock"></i> </span> <span class=post-meta-item-text>阅读时长 ≈</span> <span>1 分钟</span> </span></div></div></header><div class=post-body itemprop=articleBody><p><strong>1.1 Word2Vec（CBOW & Skip-gram）</strong><p><strong>概念</strong>：<p>Word2Vec 是一种<strong>将单词映射到向量空间</strong>的技术，由 Google 在 2013 年提出。它主要有两种训练方式：<p>• <strong>CBOW（Continuous Bag of Words）</strong>：用<strong>上下文词</strong>预测<strong>目标词</strong>，适用于数据较少的情况。<br> • <strong>Skip-gram</strong>：用<strong>目标词</strong>预测<strong>上下文词</strong>，在大规模数据上表现更好。<p><strong>面试考点</strong>：<ol><li><strong>Word2Vec 为什么能捕捉语义？</strong><br> • 因为它通过上下文关系学习<strong>分布式词表示</strong>，相似的词会被映射到相近的向量空间。<li><strong>Word2Vec 的缺点？</strong><br> • 不能处理<strong>多义词（polysemy）</strong>，比如 “bank”（银行/河岸）只有一个向量表示。<br> • 无法处理 OOV（未登录词），需要提前构建词表。<li><strong>如何优化 Word2Vec？</strong><br> • <strong>负采样（Negative Sampling）</strong>：加速训练并减少计算复杂度。<br> • <strong>层次 Softmax（Hierarchical Softmax）</strong>：优化计算效率。</ol></div><footer class=post-footer><div class=post-eof></div></footer></article></div><div class=post-block><article class=post-content itemscope itemtype=http://schema.org/Article><link href=https://blog.river9.top/2025/05/04/interview/%E6%A6%82%E7%8E%87%E8%AE%BA/ itemprop=mainEntityOfPage><span hidden itemprop=author itemscope itemtype=http://schema.org/Person> <meta content=/favicon/cirno_pat.gif itemprop=image> <meta content="River June" itemprop=name> </span><span hidden itemprop=publisher itemscope itemtype=http://schema.org/Organization> <meta content="Junetheriver's Blog" itemprop=name> <meta content="An Idiot to Anything" itemprop=description> </span><span hidden itemprop=post itemscope itemtype=http://schema.org/CreativeWork> <meta content="undefined | Junetheriver's Blog" itemprop=name> <meta itemprop=description> </span><header class=post-header><h2 itemprop="name headline" class=post-title><a class=post-title-link href=/2025/05/04/interview/%E6%A6%82%E7%8E%87%E8%AE%BA/ itemprop=url>概率论</a></h2><div class=post-meta-container><div class=post-meta><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-calendar"></i> </span> <span class=post-meta-item-text>发表于</span> <time itemprop="dateCreated datePublished" title="创建时间：2025-05-04 03:04:40 / 修改时间：11:15:44" datetime=2025-05-04T03:04:40+08:00>2025-05-04</time> </span><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-folder"></i> </span> <span class=post-meta-item-text>分类于</span> <span itemprop=about itemscope itemtype=http://schema.org/Thing> <a href=/categories/interview/ itemprop=url rel=index><span itemprop=name>interview</span></a> </span> </span><span class=post-meta-break></span><span class=post-meta-item title=本文字数> <span class=post-meta-item-icon> <i class="far fa-file-word"></i> </span> <span class=post-meta-item-text>本文字数：</span> <span>220</span> </span><span class=post-meta-item title=阅读时长> <span class=post-meta-item-icon> <i class="far fa-clock"></i> </span> <span class=post-meta-item-text>阅读时长 ≈</span> <span>1 分钟</span> </span></div></div></header><div class=post-body itemprop=articleBody><h2 id=拒绝采样><a class=markdownIt-Anchor href=#拒绝采样></a> 拒绝采样</h2><p><img alt data-src=/interview/images/Pasted%20image%2020250220164952.png><h3 id=llm-的拒绝采样><a class=markdownIt-Anchor href=#llm-的拒绝采样></a> LLM 的拒绝采样</h3><p>LLM 的拒绝采样操作起来非常简单：让自己的模型针对 prompt 生成多个候选 response，然后用 reward_model 筛选出来高质量的 response （也可以是 pair 对），拿来再次进行训练。<p>解剖这个过程：<ol><li>提议分布是我们自己的模型，目标分布是最好的语言模型；<li>prompt + response = 一个采样结果；<li>do_sample 多次 = 缩放提议分布（也可以理解为扔多次骰子）；<li>采样结果得到 reward_model 的认可 = 符合目标分布。</ol><p>经过这一番操作，我们能获得很多的训练样本，“<strong>这些样本既符合最好的语言模型的说话习惯，又不偏离原始语言模型的表达习惯</strong> ”，学习它们就能让我们的模型更接近最好的语言模型。</div><footer class=post-footer><div class=post-eof></div></footer></article></div><div class=post-block><article class=post-content itemscope itemtype=http://schema.org/Article><link href=https://blog.river9.top/2025/05/04/interview/%E6%90%9C%E5%B9%BF%E6%8E%A8/ itemprop=mainEntityOfPage><span hidden itemprop=author itemscope itemtype=http://schema.org/Person> <meta content=/favicon/cirno_pat.gif itemprop=image> <meta content="River June" itemprop=name> </span><span hidden itemprop=publisher itemscope itemtype=http://schema.org/Organization> <meta content="Junetheriver's Blog" itemprop=name> <meta content="An Idiot to Anything" itemprop=description> </span><span hidden itemprop=post itemscope itemtype=http://schema.org/CreativeWork> <meta content="undefined | Junetheriver's Blog" itemprop=name> <meta itemprop=description> </span><header class=post-header><h2 itemprop="name headline" class=post-title><a class=post-title-link href=/2025/05/04/interview/%E6%90%9C%E5%B9%BF%E6%8E%A8/ itemprop=url>搜广推</a></h2><div class=post-meta-container><div class=post-meta><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-calendar"></i> </span> <span class=post-meta-item-text>发表于</span> <time itemprop="dateCreated datePublished" title="创建时间：2025-05-04 03:04:40 / 修改时间：11:06:39" datetime=2025-05-04T03:04:40+08:00>2025-05-04</time> </span><span class=post-meta-break></span><span class=post-meta-item title=本文字数> <span class=post-meta-item-icon> <i class="far fa-file-word"></i> </span> <span class=post-meta-item-text>本文字数：</span> <span>1.2k</span> </span><span class=post-meta-item title=阅读时长> <span class=post-meta-item-icon> <i class="far fa-clock"></i> </span> <span class=post-meta-item-text>阅读时长 ≈</span> <span>4 分钟</span> </span></div></div></header><div class=post-body itemprop=articleBody><ol><li>手撕代码：三数之和<li>激活函数都有那些？<li>sigmoid和relu的优劣性<li>梯度消失什么原因？怎么避免？<li>优化器了解哪些？<li>adam和adagrad有什么区别？分别适合什么场景？<li>损失函数主流有哪些？为什么分类任务用ce？<li>项目相关：项目中用了几层cnn，1*1的cnn有什么作用？<li>对推荐链路有了解吗？分别发挥什么作用？<li>精排都有哪些主流模型？<li>粗排和精排的区别是什么？</ol><p><strong>1.1 什么是推荐系统？</strong><br> 推荐系统是一种利用数据分析、机器学习等技术，<strong>为用户提供个性化内容</strong>的系统，常见于电商、视频、音乐、社交等平台。<p><strong>1.2 推荐系统的作用？</strong><br> • <strong>提升用户体验</strong>：帮助用户快速找到感兴趣的内容<br> • <strong>提高用户留存</strong>：增加用户粘性，提升活跃度<br> • <strong>提升转化率</strong>：提高点击率、购买率等关键指标<br> • <strong>优化内容分发</strong>：高效匹配用户与内容<p><strong>1.3 推荐系统的意义？</strong><br> • <strong>个性化服务</strong>：不同用户看到不同的内容<br> • <strong>信息过载问题</strong>：减少用户的筛选成本<br> • <strong>商业价值</strong>：提升平台收益，如广告点击率、销售转化率<p><strong>1.4 推荐系统要解决的问题？</strong><br> • <strong>冷启动问题</strong>（新用户、新物品缺少历史数据）<br> • <strong>数据稀疏性</strong>（用户行为数据有限，难以建模）<br> • <strong>多样性 vs. 相关性</strong>（避免推荐过于单一，保持多样性）<br> • <strong>实时性</strong>（如何快速更新推荐结果）<br> • <strong>用户隐私保护</strong>（如何在推荐中兼顾隐私）<p><strong>1.5 常用的推荐系统的逻辑框架？</strong><p>推荐系统一般包括四个层次：<ol><li><strong>召回（Recall）</strong>：从海量数据中筛选出相关内容<li><strong>粗排（Pre-Ranking）</strong>：利用轻量模型（如LR、GBDT）对召回结果进行初步排序<li><strong>精排（Ranking）</strong>：用复杂模型（如深度学习）对候选集排序<li><strong>重排（Re-Ranking）</strong>：优化多样性、新颖性、用户体验</ol><p><strong>1.6 常用的推荐系统的技术架构？</strong><p>推荐系统架构一般包括：<ol><li><strong>数据层</strong>（日志采集、特征工程）<li><strong>算法层</strong>（召回、排序、重排）<li><strong>服务层</strong>（推荐引擎、AB测试）<li><strong>应用层</strong>（用户界面、交互反馈）</ol><p><strong>1.7 推荐系统算法工程师日常解决的问题？</strong><p>• <strong>优化召回策略</strong>（如协同过滤、内容推荐）<br> • <strong>改进排序模型</strong>（提升精排模型效果）<br> • <strong>特征工程优化</strong>（构造更有效的用户、物品特征）<br> • <strong>AB测试和效果评估</strong>（调整推荐算法，提高业务指标）<p><strong>1.8 推荐系统算法工程师处理的数据部分？</strong><p>• <strong>用户数据</strong>（点击、浏览、点赞、收藏、购买等）<br> • <strong>物品数据</strong>（商品、视频、文章等的内容信息）<br> • <strong>行为数据</strong>（用户与物品的交互，如时间、地点）<br> 最终得到的是<strong>用于训练推荐模型的特征数据</strong>。<p><strong>1.9 推荐系统算法工程师处理的模型部分？</strong><p>• <strong>召回模型</strong>（协同过滤、矩阵分解、Embedding）<br> • <strong>排序模型</strong>（LR、GBDT、DeepFM、DIN、Transformer）<br> 最终得到的是<strong>用于预测用户偏好的推荐模型</strong>。<p><strong>1.10 模型训练的方式？</strong><p>• <strong>离线训练</strong>（定期批量训练，更新模型）<br> • <strong>在线训练</strong>（实时学习用户行为，快速调整模型）<br> • <strong>迁移学习</strong>（用已有数据快速训练新模型）<br> • <strong>多任务学习</strong>（同时优化多个目标，如CTR和CVR）<p><strong>1.11 推荐系统的流程是什么？</strong><ol><li><strong>数据采集</strong>（用户行为日志、内容数据）<li><strong>特征工程</strong>（构造用户、物品、交互特征）<li><strong>召回</strong>（初步筛选候选集）<li><strong>排序</strong>（根据模型分数排序）<li><strong>重排</strong>（优化用户体验，如多样性）<li><strong>推荐展示</strong>（给用户提供推荐列表）<li><strong>反馈优化</strong>（用户点击、跳出率等数据用于优化推荐）</ol><p><strong>1.12 推荐系统与搜索、广告的异同？</strong><table><thead><tr><th><strong>维度</strong><th><strong>推荐系统</strong><th><strong>搜索</strong><th><strong>广告</strong><tbody><tr><td><strong>用户输入</strong><td>无需输入，系统主动推荐<td>用户输入关键词<td>依据广告竞价和用户画像<tr><td><strong>核心目标</strong><td>提高用户体验，增加粘性<td>帮助用户找到目标内容<td>提高广告转化率<tr><td><strong>算法原理</strong><td>召回 + 排序<td>检索 + 排序<td>竞价 + 排序<tr><td><strong>业务场景</strong><td>视频、电商、社交<td>购物、知识问答<td>电商、内容平台、搜索引擎</table><p><strong>1.13 推荐系统整体架构？</strong><ol start=8><li><strong>数据层</strong>（日志、特征工程）<li><strong>召回层</strong>（用户行为、物品匹配）<li><strong>粗排层</strong>（轻量级排序模型）<li><strong>精排层</strong>（复杂深度学习模型）<li><strong>重排层</strong>（多样性、探索机制）<li><strong>在线服务</strong>（推荐 API、AB 测试、日志反馈）</ol></div><footer class=post-footer><div class=post-eof></div></footer></article></div><div class=post-block><article class=post-content itemscope itemtype=http://schema.org/Article><link href=https://blog.river9.top/2025/05/04/interview/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/ itemprop=mainEntityOfPage><span hidden itemprop=author itemscope itemtype=http://schema.org/Person> <meta content=/favicon/cirno_pat.gif itemprop=image> <meta content="River June" itemprop=name> </span><span hidden itemprop=publisher itemscope itemtype=http://schema.org/Organization> <meta content="Junetheriver's Blog" itemprop=name> <meta content="An Idiot to Anything" itemprop=description> </span><span hidden itemprop=post itemscope itemtype=http://schema.org/CreativeWork> <meta content="undefined | Junetheriver's Blog" itemprop=name> <meta itemprop=description> </span><header class=post-header><h2 itemprop="name headline" class=post-title><a class=post-title-link href=/2025/05/04/interview/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/ itemprop=url>机器学习</a></h2><div class=post-meta-container><div class=post-meta><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-calendar"></i> </span> <span class=post-meta-item-text>发表于</span> <time itemprop="dateCreated datePublished" title="创建时间：2025-05-04 03:04:40 / 修改时间：11:05:54" datetime=2025-05-04T03:04:40+08:00>2025-05-04</time> </span><span class=post-meta-break></span><span class=post-meta-item title=本文字数> <span class=post-meta-item-icon> <i class="far fa-file-word"></i> </span> <span class=post-meta-item-text>本文字数：</span> <span>243</span> </span><span class=post-meta-item title=阅读时长> <span class=post-meta-item-icon> <i class="far fa-clock"></i> </span> <span class=post-meta-item-text>阅读时长 ≈</span> <span>1 分钟</span> </span></div></div></header><div class=post-body itemprop=articleBody><ol><li>激活函数有哪些？</ol><ul><li>sigmoid <ul><li>值域(0,1)<li>梯度消失<li>二分类</ul><li>双曲正切tanh <ul><li>(-1,1)<li>比sigmoid梯度更大，收敛更快<li>梯度消失</ul><li>ReLU <ul><li>计算简单，收敛快<li>可能出现神经元死亡</ul><li>LeakyReLU</ul><h3 id=1-了解-random-walk-吗图怎么得到-embedding><a class=markdownIt-Anchor href=#1-了解-random-walk-吗图怎么得到-embedding></a> <strong>1. 了解 Random Walk 吗？图怎么得到 embedding？</strong></h3><p><strong>回答：</strong> <strong>Random Walk</strong> 是图中随机游走的一种方法，常用于图的表示学习。它的基本思想是在图上随机选择一条边走到另一个节点，然后反复进行。<p><strong>得到图嵌入（Embedding）</strong>：<ul><li><strong>Node2Vec</strong> 和 <strong>DeepWalk</strong> 是基于 Random Walk 的经典图嵌入方法。它们通过在图上进行<strong>随机游走</strong>，然后使用 <strong>Skip-Gram 模型</strong>（类似 Word2Vec）来训练每个节点的嵌入表示。 <ul><li><strong>Node2Vec</strong> 改进了传统的深度游走，通过调整游走策略（深度优先和广度优先）来捕获不同层次的节点信息。<li><strong>DeepWalk</strong> 通过类似 Word2Vec 的模型（CBOW 或 Skip-gram）来学习节点的嵌入。</ul></ul></div><footer class=post-footer><div class=post-eof></div></footer></article></div><div class=post-block><article class=post-content itemscope itemtype=http://schema.org/Article><link href=https://blog.river9.top/2025/05/04/interview/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%B8%B8%E8%A7%81%E9%9D%A2%E7%BB%8F/ itemprop=mainEntityOfPage><span hidden itemprop=author itemscope itemtype=http://schema.org/Person> <meta content=/favicon/cirno_pat.gif itemprop=image> <meta content="River June" itemprop=name> </span><span hidden itemprop=publisher itemscope itemtype=http://schema.org/Organization> <meta content="Junetheriver's Blog" itemprop=name> <meta content="An Idiot to Anything" itemprop=description> </span><span hidden itemprop=post itemscope itemtype=http://schema.org/CreativeWork> <meta content="undefined | Junetheriver's Blog" itemprop=name> <meta itemprop=description> </span><header class=post-header><h2 itemprop="name headline" class=post-title><a class=post-title-link href=/2025/05/04/interview/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%B8%B8%E8%A7%81%E9%9D%A2%E7%BB%8F/ itemprop=url>大模型</a></h2><div class=post-meta-container><div class=post-meta><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-calendar"></i> </span> <span class=post-meta-item-text>发表于</span> <time itemprop="dateCreated datePublished" title="创建时间：2025-05-04 03:04:40 / 修改时间：11:12:08" datetime=2025-05-04T03:04:40+08:00>2025-05-04</time> </span><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-folder"></i> </span> <span class=post-meta-item-text>分类于</span> <span itemprop=about itemscope itemtype=http://schema.org/Thing> <a href=/categories/interview/ itemprop=url rel=index><span itemprop=name>interview</span></a> </span> </span><span class=post-meta-break></span><span class=post-meta-item title=本文字数> <span class=post-meta-item-icon> <i class="far fa-file-word"></i> </span> <span class=post-meta-item-text>本文字数：</span> <span>627</span> </span><span class=post-meta-item title=阅读时长> <span class=post-meta-item-icon> <i class="far fa-clock"></i> </span> <span class=post-meta-item-text>阅读时长 ≈</span> <span>2 分钟</span> </span></div></div></header><div class=post-body itemprop=articleBody><p>[toc]<h2 id=deepseek><a class=markdownIt-Anchor href=#deepseek></a> DeepSeek</h2><p>[[DeepSeek]]<h2 id=拒绝采样><a class=markdownIt-Anchor href=#拒绝采样></a> 拒绝采样</h2><p>[[概率论#LLM 的拒绝采样]]<h2 id=显存计算><a class=markdownIt-Anchor href=#显存计算></a> 显存计算</h2><h3 id=推理><a class=markdownIt-Anchor href=#推理></a> 推理</h3><ul><li>int8： 模型显存 = 1*参数量（Byte）<li>fp16, bf16: 模型显存 = 2*参数量（Byte）<li>fp32: 模型显存 = 4*参数量（Byte）</ul><p>混合精度（Mixed-precision）最后存储的类型也是fp32，公式也适合混合精度。<h3 id=训练><a class=markdownIt-Anchor href=#训练></a> 训练</h3><p>训练显存消耗：模型参数(Model) + 优化器状态(Optimizer status) + 梯度 (Gradient) + 激活值 (Activation)<p>静态值：模型参数和优化器状态<br> 动态值：激活值和梯度值<p>下面默认参数都是4Byte<h4 id=模型参数><a class=markdownIt-Anchor href=#模型参数></a> 模型参数</h4><p>同推理<h4 id=优化器状态><a class=markdownIt-Anchor href=#优化器状态></a> 优化器状态</h4><p>常见优化器Adam：Momentum和一个Variance，混合精度训练中再加一个模型参数副本<ul><li>模型副本 4Bytes （副本存32位的）<li>Momentum 4Byte<li>Variance 4Byte</ul><p>那就是参数副本+momentum+variance = 32 * 3<h4 id=梯度值><a class=markdownIt-Anchor href=#梯度值></a> 梯度值</h4><p>梯度的数据类型和模型参数一直，因此和模型参数同样规模<h4 id=激活值><a class=markdownIt-Anchor href=#激活值></a> 激活值</h4><p>激活值的大小跟模型参数、重计算、并行策略等相关，这里我们参考Megtron论文里面给的计算公式，来求解激活值所占用的显存大小。<p class=katex-block><span class=katex-display><span class=katex><span class=katex-mathml><math display=block xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>s</mi><mo>∗</mo><mi>b</mi><mo>∗</mo><mi>h</mi><mo>∗</mo><mo stretchy=false>(</mo><mn>34</mn><mo>+</mo><mn>5</mn><mo>∗</mo><mi>a</mi><mo>∗</mo><mi>s</mi><mi mathvariant=normal>/</mi><mi>h</mi><mo stretchy=false>)</mo><mo>∗</mo><mi>L</mi><mo>∗</mo><mi>γ</mi></mrow><annotation encoding=application/x-tex>s*b*h*(34+5*a*s/h) *L *\gamma </annotation></semantics></math></span><span aria-hidden=true class=katex-html><span class=base><span class=strut style=height:0.46528em;vertical-align:0em;></span><span class="mord mathnormal">s</span><span class=mspace style=margin-right:0.2222222222222222em;></span><span class=mbin>∗</span><span class=mspace style=margin-right:0.2222222222222222em;></span></span><span class=base><span class=strut style=height:0.69444em;vertical-align:0em;></span><span class="mord mathnormal">b</span><span class=mspace style=margin-right:0.2222222222222222em;></span><span class=mbin>∗</span><span class=mspace style=margin-right:0.2222222222222222em;></span></span><span class=base><span class=strut style=height:0.69444em;vertical-align:0em;></span><span class="mord mathnormal">h</span><span class=mspace style=margin-right:0.2222222222222222em;></span><span class=mbin>∗</span><span class=mspace style=margin-right:0.2222222222222222em;></span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em;></span><span class=mopen>(</span><span class=mord>3</span><span class=mord>4</span><span class=mspace style=margin-right:0.2222222222222222em;></span><span class=mbin>+</span><span class=mspace style=margin-right:0.2222222222222222em;></span></span><span class=base><span class=strut style=height:0.64444em;vertical-align:0em;></span><span class=mord>5</span><span class=mspace style=margin-right:0.2222222222222222em;></span><span class=mbin>∗</span><span class=mspace style=margin-right:0.2222222222222222em;></span></span><span class=base><span class=strut style=height:0.46528em;vertical-align:0em;></span><span class="mord mathnormal">a</span><span class=mspace style=margin-right:0.2222222222222222em;></span><span class=mbin>∗</span><span class=mspace style=margin-right:0.2222222222222222em;></span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em;></span><span class="mord mathnormal">s</span><span class=mord>/</span><span class="mord mathnormal">h</span><span class=mclose>)</span><span class=mspace style=margin-right:0.2222222222222222em;></span><span class=mbin>∗</span><span class=mspace style=margin-right:0.2222222222222222em;></span></span><span class=base><span class=strut style=height:0.68333em;vertical-align:0em;></span><span class="mord mathnormal">L</span><span class=mspace style=margin-right:0.2222222222222222em;></span><span class=mbin>∗</span><span class=mspace style=margin-right:0.2222222222222222em;></span></span><span class=base><span class=strut style=height:0.625em;vertical-align:-0.19444em;></span><span class="mord mathnormal" style=margin-right:0.05556em;>γ</span></span></span></span></span><ul><li>s 序列长度（sequence length), tokens的量<li>b 微批量大小（microbatch size）<li>h 隐藏层大小（hidden dimension size）<li>a attention的头数 （number of attention heads）<li>L transformer模型的层数<li>λ 比例系数，当为fp16时 值等于1 / (1024 * 1024 * 1024)。</ul><p>如果全部重计算：<p class=katex-block><span class=katex-display><span class=katex><span class=katex-mathml><math display=block xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>s</mi><mo>∗</mo><mi>b</mi><mo>∗</mo><mi>h</mi><mo>∗</mo><mo stretchy=false>(</mo><mn>2</mn><mo stretchy=false>)</mo><mo>∗</mo><mi>L</mi><mo>∗</mo><mi>γ</mi></mrow><annotation encoding=application/x-tex>s*b*h*(2)*L*\gamma </annotation></semantics></math></span><span aria-hidden=true class=katex-html><span class=base><span class=strut style=height:0.46528em;vertical-align:0em;></span><span class="mord mathnormal">s</span><span class=mspace style=margin-right:0.2222222222222222em;></span><span class=mbin>∗</span><span class=mspace style=margin-right:0.2222222222222222em;></span></span><span class=base><span class=strut style=height:0.69444em;vertical-align:0em;></span><span class="mord mathnormal">b</span><span class=mspace style=margin-right:0.2222222222222222em;></span><span class=mbin>∗</span><span class=mspace style=margin-right:0.2222222222222222em;></span></span><span class=base><span class=strut style=height:0.69444em;vertical-align:0em;></span><span class="mord mathnormal">h</span><span class=mspace style=margin-right:0.2222222222222222em;></span><span class=mbin>∗</span><span class=mspace style=margin-right:0.2222222222222222em;></span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em;></span><span class=mopen>(</span><span class=mord>2</span><span class=mclose>)</span><span class=mspace style=margin-right:0.2222222222222222em;></span><span class=mbin>∗</span><span class=mspace style=margin-right:0.2222222222222222em;></span></span><span class=base><span class=strut style=height:0.68333em;vertical-align:0em;></span><span class="mord mathnormal">L</span><span class=mspace style=margin-right:0.2222222222222222em;></span><span class=mbin>∗</span><span class=mspace style=margin-right:0.2222222222222222em;></span></span><span class=base><span class=strut style=height:0.625em;vertical-align:-0.19444em;></span><span class="mord mathnormal" style=margin-right:0.05556em;>γ</span></span></span></span></span><h4 id=单卡与并行><a class=markdownIt-Anchor href=#单卡与并行></a> 单卡与并行</h4><p class=katex-block><span class=katex-display><span class=katex><span class=katex-mathml><math display=block xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mtext>TotalMemory</mtext><mo>=</mo><mtext>Model</mtext><mo>+</mo><mtext>Optimizer</mtext><mo>+</mo><mtext>Activation</mtext><mo>+</mo><mtext>Gradient</mtext></mrow><annotation encoding=application/x-tex>\text{TotalMemory} = \text{Model} + \text{Optimizer} + \text{Activation} + \text{Gradient} </annotation></semantics></math></span><span aria-hidden=true class=katex-html><span class=base><span class=strut style=height:0.8888799999999999em;vertical-align:-0.19444em;></span><span class="mord text"><span class=mord>TotalMemory</span></span><span class=mspace style=margin-right:0.2777777777777778em;></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2777777777777778em;></span></span><span class=base><span class=strut style=height:0.77777em;vertical-align:-0.08333em;></span><span class="mord text"><span class=mord>Model</span></span><span class=mspace style=margin-right:0.2222222222222222em;></span><span class=mbin>+</span><span class=mspace style=margin-right:0.2222222222222222em;></span></span><span class=base><span class=strut style=height:0.8777699999999999em;vertical-align:-0.19444em;></span><span class="mord text"><span class=mord>Optimizer</span></span><span class=mspace style=margin-right:0.2222222222222222em;></span><span class=mbin>+</span><span class=mspace style=margin-right:0.2222222222222222em;></span></span><span class=base><span class=strut style=height:0.76666em;vertical-align:-0.08333em;></span><span class="mord text"><span class=mord>Activation</span></span><span class=mspace style=margin-right:0.2222222222222222em;></span><span class=mbin>+</span><span class=mspace style=margin-right:0.2222222222222222em;></span></span><span class=base><span class=strut style=height:0.69444em;vertical-align:0em;></span><span class="mord text"><span class=mord>Gradient</span></span></span></span></span></span><ul><li>TP: tensor并行：Megatron-LM<li>SP: 序列并行<li>PP: pipeline并行<li>Zero：参数服务器 <ul><li>Zero1：优化器参数分散到N张卡<li>Zero2：优化器和梯度分散到N张卡<li>Zero3：优化器、梯度、模型都分散到N张卡，并且还要算上新引入的参数LiveParams，用于决定哪些参数加载到GPU中</ul></ul><p class=katex-block><span class=katex-display><span class=katex><span class=katex-mathml><math display=block xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mtext>TotalMemory</mtext><mo>=</mo><mtext>Model</mtext><mi mathvariant=normal>/</mi><mo stretchy=false>(</mo><mi>P</mi><mi>P</mi><mo>∗</mo><mi>T</mi><mi>P</mi><mo stretchy=false>)</mo><mo>+</mo><mtext>Optimizer</mtext><mi mathvariant=normal>/</mi><mi>N</mi><mo>+</mo><mtext>Activation</mtext><mi mathvariant=normal>/</mi><mi>T</mi><mi>P</mi><mo>+</mo><mtext>Gradient</mtext><mi mathvariant=normal>/</mi><mi>P</mi><mi>P</mi></mrow><annotation encoding=application/x-tex>\text{TotalMemory} = \text{Model}/(PP*TP) + \text{Optimizer}/N + \text{Activation}/TP + \text{Gradient}/PP </annotation></semantics></math></span><span aria-hidden=true class=katex-html><span class=base><span class=strut style=height:0.8888799999999999em;vertical-align:-0.19444em;></span><span class="mord text"><span class=mord>TotalMemory</span></span><span class=mspace style=margin-right:0.2777777777777778em;></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2777777777777778em;></span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em;></span><span class="mord text"><span class=mord>Model</span></span><span class=mord>/</span><span class=mopen>(</span><span class="mord mathnormal" style=margin-right:0.13889em;>P</span><span class="mord mathnormal" style=margin-right:0.13889em;>P</span><span class=mspace style=margin-right:0.2222222222222222em;></span><span class=mbin>∗</span><span class=mspace style=margin-right:0.2222222222222222em;></span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em;></span><span class="mord mathnormal" style=margin-right:0.13889em;>T</span><span class="mord mathnormal" style=margin-right:0.13889em;>P</span><span class=mclose>)</span><span class=mspace style=margin-right:0.2222222222222222em;></span><span class=mbin>+</span><span class=mspace style=margin-right:0.2222222222222222em;></span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em;></span><span class="mord text"><span class=mord>Optimizer</span></span><span class=mord>/</span><span class="mord mathnormal" style=margin-right:0.10903em;>N</span><span class=mspace style=margin-right:0.2222222222222222em;></span><span class=mbin>+</span><span class=mspace style=margin-right:0.2222222222222222em;></span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em;></span><span class="mord text"><span class=mord>Activation</span></span><span class=mord>/</span><span class="mord mathnormal" style=margin-right:0.13889em;>T</span><span class="mord mathnormal" style=margin-right:0.13889em;>P</span><span class=mspace style=margin-right:0.2222222222222222em;></span><span class=mbin>+</span><span class=mspace style=margin-right:0.2222222222222222em;></span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em;></span><span class="mord text"><span class=mord>Gradient</span></span><span class=mord>/</span><span class="mord mathnormal" style=margin-right:0.13889em;>P</span><span class="mord mathnormal" style=margin-right:0.13889em;>P</span></span></span></span></span><h2 id=lora><a class=markdownIt-Anchor href=#lora></a> LORA</h2><p>Lora方法的核心是在大型语言模型上对指定参数增加额外的低秩矩阵，也就是在原始PLM旁边增加一个旁路，做一个降维再升维的操作。并在模型训练过程中，固定PLM的参数，只训练降维矩阵A与升维矩阵B。<p>Ptuning方法的核心是使用可微的virtual token替换了原来的discrete tokens，且仅加入到输入层，并使用prompt<h2 id=stable-diffusion原理><a class=markdownIt-Anchor href=#stable-diffusion原理></a> Stable Diffusion原理</h2><p>[[Stable Diffusion]]<ul><li>TextEncoder <ul><li>CLIP</ul><li>Diffusion<li>VAE</ul><h2 id=大模型的模型架构><a class=markdownIt-Anchor href=#大模型的模型架构></a> 大模型的模型架构</h2><ul><li>Only-encoder<li>Only-decoder<li>Encoder-Decoder</ul></div><footer class=post-footer><div class=post-eof></div></footer></article></div><div class=post-block><article class=post-content itemscope itemtype=http://schema.org/Article><link href=https://blog.river9.top/2025/05/04/interview/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/ itemprop=mainEntityOfPage><span hidden itemprop=author itemscope itemtype=http://schema.org/Person> <meta content=/favicon/cirno_pat.gif itemprop=image> <meta content="River June" itemprop=name> </span><span hidden itemprop=publisher itemscope itemtype=http://schema.org/Organization> <meta content="Junetheriver's Blog" itemprop=name> <meta content="An Idiot to Anything" itemprop=description> </span><span hidden itemprop=post itemscope itemtype=http://schema.org/CreativeWork> <meta content="undefined | Junetheriver's Blog" itemprop=name> <meta itemprop=description> </span><header class=post-header><h2 itemprop="name headline" class=post-title><a class=post-title-link href=/2025/05/04/interview/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/ itemprop=url>强化学习</a></h2><div class=post-meta-container><div class=post-meta><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-calendar"></i> </span> <span class=post-meta-item-text>发表于</span> <time itemprop="dateCreated datePublished" title="创建时间：2025-05-04 03:04:40 / 修改时间：11:06:18" datetime=2025-05-04T03:04:40+08:00>2025-05-04</time> </span><span class=post-meta-break></span><span class=post-meta-item title=本文字数> <span class=post-meta-item-icon> <i class="far fa-file-word"></i> </span> <span class=post-meta-item-text>本文字数：</span> <span>20</span> </span><span class=post-meta-item title=阅读时长> <span class=post-meta-item-icon> <i class="far fa-clock"></i> </span> <span class=post-meta-item-text>阅读时长 ≈</span> <span>1 分钟</span> </span></div></div></header><div class=post-body itemprop=articleBody><h2 id=prm基于过程的奖励模型><a class=markdownIt-Anchor href=#prm基于过程的奖励模型></a> PRM：基于过程的奖励模型</h2><h2 id=orm基于结果的奖励模型><a class=markdownIt-Anchor href=#orm基于结果的奖励模型></a> ORM：基于结果的奖励模型</h2></div><footer class=post-footer><div class=post-eof></div></footer></article></div><div class=post-block><article class=post-content itemscope itemtype=http://schema.org/Article><link href=https://blog.river9.top/2025/05/04/interview/Qwen3/ itemprop=mainEntityOfPage><span hidden itemprop=author itemscope itemtype=http://schema.org/Person> <meta content=/favicon/cirno_pat.gif itemprop=image> <meta content="River June" itemprop=name> </span><span hidden itemprop=publisher itemscope itemtype=http://schema.org/Organization> <meta content="Junetheriver's Blog" itemprop=name> <meta content="An Idiot to Anything" itemprop=description> </span><span hidden itemprop=post itemscope itemtype=http://schema.org/CreativeWork> <meta content="undefined | Junetheriver's Blog" itemprop=name> <meta itemprop=description> </span><header class=post-header><h2 itemprop="name headline" class=post-title><a class=post-title-link href=/2025/05/04/interview/Qwen3/ itemprop=url>Qwen3</a></h2><div class=post-meta-container><div class=post-meta><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-calendar"></i> </span> <span class=post-meta-item-text>发表于</span> <time itemprop="dateCreated datePublished" title="创建时间：2025-05-04 03:04:40 / 修改时间：11:08:47" datetime=2025-05-04T03:04:40+08:00>2025-05-04</time> </span><span class=post-meta-break></span><span class=post-meta-item title=本文字数> <span class=post-meta-item-icon> <i class="far fa-file-word"></i> </span> <span class=post-meta-item-text>本文字数：</span> <span>943</span> </span><span class=post-meta-item title=阅读时长> <span class=post-meta-item-icon> <i class="far fa-clock"></i> </span> <span class=post-meta-item-text>阅读时长 ≈</span> <span>3 分钟</span> </span></div></div></header><div class=post-body itemprop=articleBody><ul><li>Dense and Mixture-of-Experts<li>无缝切换：思考模式和飞思考模式<li>推理能力加强<li>更好的人类偏好对齐<li>agent能力<li>100+语言和方言</ul><h2 id=模型><a class=markdownIt-Anchor href=#模型></a> 模型</h2><ul><li>Qwen3-235B-A22B：235B总参数和22B激活参数 <ul><li>48层，Q:32，KV:4，Experts（total/activated): 128 / 8，Context Length: 128K</ul><li>Qwen3-30B-A3B：30B总参数和3B激活参数<li>Qwen3-32/14/8/4/1.7/0.6B</ul><h2 id=预训练><a class=markdownIt-Anchor href=#预训练></a> 预训练</h2><p>在36T token上去训练，是Qwen2.5的两倍（18T）<br> 来源：web, pdf, 用Qwen2.5-VL提取文档中的文本并用Qwen2.5提升质量<p>预训练过程共分为三个阶段。<p>在第一阶段（S1），模型在超过30T个token上进行预训练，使用的上下文长度为4K标注符。这一阶段使模型掌握了基本的语言能力和通用知识。<p>在第二阶段（S2），我们优化了训练数据集，提高了知识密集型数据的占比，例如STEM领域、编程和推理任务。随后模型在额外的5T标注符号上继续进行预训练。<p>在最后阶段，我们采用高质量的长上下文数据，将上下文长度扩展至32K标注符号，以确保模型能够有效处理更长的输入内容。<h2 id=post-training><a class=markdownIt-Anchor href=#post-training></a> Post-Training</h2><p>![[Pasted image 20250430170954.png]]<p>为了开发一个既具备逐步推理能力又能快速响应的混合模型，我们设计并实施了一个四阶段的训练流程，具体包括：(1) 长链式思维（CoT）冷启动，(2) 基于推理的强化学习（RL），(3) 思维模式融合，以及 (4) 通用强化学习。<p>在第一阶段，我们使用涵盖数学、编程、逻辑推理和STEM问题等多种任务和领域的多样化长链式思维数据对模型进行微调，旨在赋予模型基本的推理能力。第二阶段重点在于扩大强化学习所使用的计算资源，通过基于规则的奖励机制提升模型的探索与利用能力。<p>第三阶段通过在长链式思维数据和常规指令微调数据的组合上进行微调，将“非思维”能力融合进已具备推理能力的模型中。这些数据由第二阶段强化后的思维模型生成，从而实现推理与快速响应能力的自然融合。最后，在第四阶段，我们在20多个通用领域任务上应用强化学习，以进一步增强模型的通用能力，并纠正不期望的行为。这些任务包括指令遵循、格式遵循、代理执行能力等。<p>![[Pasted image 20250430171232.png]]<h2 id=future-work><a class=markdownIt-Anchor href=#future-work></a> Future work</h2><p>Qwen3 是我们迈向通用人工智能（AGI）与超级人工智能（ASI）进程中的重要里程碑。通过扩大预训练与强化学习（RL）的规模，我们实现了更高层次的智能水平。同时，Qwen3 实现了思维模式与非思维模式的无缝融合，允许用户灵活控制推理资源预算。此外，我们还拓展了对多种语言的支持，显著提升了全球可达性。<p>展望未来，我们将从多个维度持续优化模型，重点包括改进模型架构与训练方法，以实现若干关键目标：扩大数据规模、增加模型容量、延长上下文长度、拓展多模态能力，并推动融合环境反馈的强化学习，以支持更长跨度的推理。我们相信，行业正从“训练模型”的阶段过渡到“训练智能体”的新阶段，而我们的下一代模型将为每个人的工作与生活带来实质性的进步。<p>![[Pasted image 20250430171715.png]]</div><footer class=post-footer><div class=post-eof></div></footer></article></div><div class=post-block><article class=post-content itemscope itemtype=http://schema.org/Article><link href=https://blog.river9.top/2025/05/04/interview/%E5%8F%8D%E5%90%91%E6%8F%90%E9%97%AE/ itemprop=mainEntityOfPage><span hidden itemprop=author itemscope itemtype=http://schema.org/Person> <meta content=/favicon/cirno_pat.gif itemprop=image> <meta content="River June" itemprop=name> </span><span hidden itemprop=publisher itemscope itemtype=http://schema.org/Organization> <meta content="Junetheriver's Blog" itemprop=name> <meta content="An Idiot to Anything" itemprop=description> </span><span hidden itemprop=post itemscope itemtype=http://schema.org/CreativeWork> <meta content="undefined | Junetheriver's Blog" itemprop=name> <meta itemprop=description> </span><header class=post-header><h2 itemprop="name headline" class=post-title><a class=post-title-link href=/2025/05/04/interview/%E5%8F%8D%E5%90%91%E6%8F%90%E9%97%AE/ itemprop=url>反向提问</a></h2><div class=post-meta-container><div class=post-meta><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-calendar"></i> </span> <span class=post-meta-item-text>发表于</span> <time itemprop="dateCreated datePublished" title="创建时间：2025-05-04 03:04:40 / 修改时间：11:12:16" datetime=2025-05-04T03:04:40+08:00>2025-05-04</time> </span><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-folder"></i> </span> <span class=post-meta-item-text>分类于</span> <span itemprop=about itemscope itemtype=http://schema.org/Thing> <a href=/categories/interview/ itemprop=url rel=index><span itemprop=name>interview</span></a> </span> </span><span class=post-meta-break></span><span class=post-meta-item title=本文字数> <span class=post-meta-item-icon> <i class="far fa-file-word"></i> </span> <span class=post-meta-item-text>本文字数：</span> <span>3.1k</span> </span><span class=post-meta-item title=阅读时长> <span class=post-meta-item-icon> <i class="far fa-clock"></i> </span> <span class=post-meta-item-text>阅读时长 ≈</span> <span>11 分钟</span> </span></div></div></header><div class=post-body itemprop=articleBody><h1 id=反向面试><a class=markdownIt-Anchor href=#反向面试></a> 反向面试</h1><blockquote><p>大部分翻译自：<span class=exturl data-url=aHR0cHM6Ly9naXRodWIuY29tL3ZpcmFwdG9yL3JldmVyc2UtaW50ZXJ2aWV3>https://github.com/viraptor/reverse-interview<i class="fa fa-external-link-alt"></i></span> ，亦有其他网友补充。</blockquote><blockquote><p>译者总结的一份适合突击记忆的简洁版 LeetCode 题解和面试问题，也欢迎 Star。<span data-url="aHR0cHM6Ly9naXRodWIuY29tL3lpZmVpa29uZy9pbnRlcnZpZXc=" class=exturl>https://github.com/yifeikong/interview<i class="fa fa-external-link-alt"></i></span></blockquote><p>下面列表里的问题对于参加技术面试的人来说可能有些用。<br> 列表里的问题并不一定适用于某个特定的职位或者工作类型，也没有排序<br> 最开始的时候这只是我自己的问题列表，但是慢慢地添加了一些我觉得可能让我对这家公司亮红牌的问题。<br> 我也注意到被我面试的人提问我的问题太少了，感觉他们挺浪费机会的。<p>如果你问过的问题没有被列出来，请提交一个 PR。<p>翻译：<p><span class=exturl data-url=aHR0cHM6Ly9naXRodWIuY29tL3ZpcmFwdG9yL3JldmVyc2UtaW50ZXJ2aWV3>English<i class="fa fa-external-link-alt"></i></span><br> <span data-url="aHR0cHM6Ly9naXRodWIuY29tL0phZVllb3BIYW4vSW50ZXJ2aWV3X1F1ZXN0aW9uX2Zvcl9CZWdpbm5lci9ibG9iL21hc3Rlci9SZXZlcnNlX0ludGVydmlldy9SRUFETUUubWQ=" class=exturl>Korean<i class="fa fa-external-link-alt"></i></span><br> <span class=exturl data-url=aHR0cHM6Ly9naXRodWIuY29tL3ZpcmFwdG9yL3JldmVyc2UtaW50ZXJ2aWV3L2Jsb2IvbWFzdGVyL3RyYW5zbGF0aW9ucy9QT1JUVUdVRVNFLm1k>Portuguese<i class="fa fa-external-link-alt"></i></span><br> <span data-url="aHR0cHM6Ly9naXRodWIuY29tL05lcm9DdWJlL3JldmVyc2UtaW50ZXJ2aWV3LXpoLXR3L2Jsb2IvbWFzdGVyL1JFQURNRS5tZA==" class=exturl>繁體中文<i class="fa fa-external-link-alt"></i></span><h2 id=预期使用方式><a class=markdownIt-Anchor href=#预期使用方式></a> 预期使用方式</h2><ul><li>检查一下哪些问题你感兴趣<li>检查一下哪些是你可以自己在网上找到答案的<li>找不到的话就向面试官提问</ul><p>绝对不要想把这个列表里的每个问题都问一遍。（尊重面试官的时间，而且你可以通过查找已经发布的答案来显示<br> 你的主动性）<p>请记住事情总是灵活的，组织的结构调整也会经常发生。拥有一个 bug 追踪系统并不会保证高效处理 bug。<br> CI/CD （持续集成系统） 也不一定保证交付时间会很短。<h1 id=职责><a class=markdownIt-Anchor href=#职责></a> 职责</h1><ul><li>On-call （电话值班）的计划或者规定是什么？值班或者遇到问题加班时候有加班费吗？<li>我的日常工作是什么？<li>有给我设定的特定目标吗？<li>团队里面初级和高级工程师的比例是多少？（有计划改变吗）<li>入职培训 (onboarding) 会是什么样的？<li>每个开发者有多大的自由来做出决定？<li>在你看来，这个工作做到什么程度算成功？<li>你期望我在最初的一个月 / 三个月能够完成什么？<li>试用期结束的时候，你会怎么样衡量我的绩效？<li>自己单独的开发活动和按部就班工作的比例大概是怎样的？<li>一个典型的一天或者一周的工作是怎样安排的？<li>对我的申请你有什么疑虑么？<li>在这份工作上，我将会和谁紧密合作？<li>我的直接上级他们的上级都是什么样的管理风格？（事无巨细还是着眼宏观）<li>我在这个岗位上应该如何发展？会有哪些机会？<li>每天预期 / 核心工作时间是多少小时？<li>我入职的岗位是新增还是接替之前离职的同事？（是否有技术债需要还）？(zh)<li>入职之后在哪个项目组，项目是新成立还是已有的？(zh)</ul><h1 id=技术><a class=markdownIt-Anchor href=#技术></a> 技术</h1><ul><li>公司常用的技术栈是什么？<li>你们怎么使用源码控制系统？<li>你们怎么测试代码？<li>你们怎么追踪 bug?<li>你们怎样监控项目？<li>你们怎么集成和部署代码改动？是使用持续集成和持续部署吗 (CI/CD)？<li>你们的基础设施搭建在版本管理系统里吗？或者是代码化的吗？<li>从计划到完成一项任务的工作流是什么样的？<li>你们如何准备故障恢复？<li>有标准的开发环境吗？是强制的吗？<li>你们需要花费多长时间来给产品搭建一个本地测试环境？（分钟 / 小时 / 天）<li>你们需要花费多长时间来响应代码或者依赖中的安全问题？<li>所有的开发者都可以使用他们电脑的本地管理员权限吗？<li>介绍一下你们的技术原则或者展望。<li>你们的代码有开发文档吗？有没有单独的供消费者阅读的文档？<li>你们有更高层次的文档吗？比如说 ER 图，数据库范式<li>你们使用静态代码分析吗？<li>你们如何管理内部和外部的数字资产？<li>你们如何管理依赖？<li>公司是否有技术分享交流活动？有的话，多久一次呢？(zh)<li>你们的数据库是怎么进行版本控制的？(zh)<li>业务需求有没有文档记录？是如何记录的？(zh)<li>你们是如何面对和解决技术债的？是否有专门的时间或者预算用于重构？<li>你们如何进行单元测试呢，是否都有单元测试的习惯?</ul><h1 id=团队><a class=markdownIt-Anchor href=#团队></a> 团队</h1><ul><li>工作是怎么组织的？<li>团队内 / 团队间的交流通常是怎样的？<li>你们使用什么工具来做项目组织？你的实际体会是什么？<li>如果遇到不同的意见怎样处理？<li>谁来设定优先级 / 计划？<li>如果团队没能赶上预期发布日期怎么办？<li>每周都会开什么类型的会议？<li>会有定期的和上级的一对一谈话吗？<li>产品 / 服务的规划是什么样的？（n 周一发布 / 持续部署 / 多个发布流 / …)<li>生产环境发生事故了怎么办？是否有不批评人而分析问题的文化？<li>有没有一些团队正在经历还尚待解决的挑战？<li>你们如何跟踪进度？<li>预期和目标是如何设定的？谁来设定？<li>Code Review 如何实施？<li>给我介绍下团队里一个典型的 sprint<li>你们如何平衡技术和商业目标？<li>你们如何共享知识？<li>团队有多大？<li>公司技术团队的架构和人员组成？(zh)<li>团队内开发、产品、运营哪一方是需求的主要提出方？哪一方更强势？(zh)</ul><h1 id=问未来的同事><a class=markdownIt-Anchor href=#问未来的同事></a> 问未来的同事</h1><ul><li>开发者倾向于从哪里学习？<li>你对在这里工作最满意的地方是？<li>最不满意的呢？<li>如果可以的话，你想改变哪里？<li>团队最老的成员在这里多久了？<li>在小团队中，有没有出现成员性格互相冲突的情况？最后是如何解决的？</ul><h1 id=公司><a class=markdownIt-Anchor href=#公司></a> 公司</h1><ul><li>公司为什么在招人？（产品发展 / 新产品 / 波动…)<li>有没有会议 / 旅行预算？使用的规定是什么？<li>晋升流程是怎样的？要求 / 预期是怎样沟通的？<li>绩效评估流程是怎样的？<li>技术和管理两条职业路径是分开的吗？<li>对于多元化招聘的现状或者观点是什么？<li>有公司级别的学习资源吗？比如电子书订阅或者在线课程？<li>有获取证书的预算吗？<li>公司的成熟度如何？（早期寻找方向 / 有内容的工作 / 维护中 / …)<li>我可以为开源项目做贡献吗？是否需要审批？<li>你认为公司未来五年或者十年会发展成什么样子？<li>公司的大多数员工是如何看待整洁代码的？<li>你上次注意到有人成长是什么时候？他们在哪方面成长了？<li>在这里成功的定义是什么？如何衡量成功？<li>有体育活动或者团建么？<li>有内部的黑客马拉松活动吗？<li>公司支持开源项目吗？<li>有竞业限制或者保密协议需要签吗？<li>你们认为公司文化中的空白是什么？<li>能够跟我说一公司处于不良情况，以及如何处理的故事吗？<li>您在这工作了多久了？您觉得体验如何？(zh)<li>大家为什么会喜欢这里？(zh)<li>公司的调薪制度是如何的？(zh)<li>公司有没有申请调岗的制度？<li>公司对于员工的心理健康和福祉有什么具体措施？<li>你对在这里工作最满意的地方是？你为什么留在这家公司？</ul><h1 id=社会问题><a class=markdownIt-Anchor href=#社会问题></a> 社会问题</h1><ul><li>你们关于多元化招聘什么看法？<li>你们的公司文化如何？你认为有什么空白么？<li>这里的工作生活平衡地怎么样？<li>公司对气候变化有什么态度吗？</ul><h1 id=冲突><a class=markdownIt-Anchor href=#冲突></a> 冲突</h1><ul><li>不同的意见如何处理？<li>如果被退回了会怎样？（“这个在预计的时间内做不完”）<li>当团队有压力并且在超负荷工作的时候怎么处理？<li>如果有人注意到了在流程或者技术等其他方面又改进的地方，怎么办？<li>当管理层的预期和工程师的绩效之间有差距的时候如何处理？<li>能给我讲一个公司深处有毒环境以及如何处理的故事吗？<li>如果在公司内你的同事因涉嫌性侵犯他人而被调查，请问你会如何处理？<li>假设我自己很不幸是在公司内被性侵的受害者，在公司内部有没有争取合法权益的渠道？</ul><h1 id=商业><a class=markdownIt-Anchor href=#商业></a> 商业</h1><ul><li>你们现在盈利吗？<li>如果没有的话，还需要多久？<li>如果有的话，年度营业额是大概有多少？（我现在的公司年度营业额是 5 亿）<li>公司的资金来源是什么？谁影响或者制定高层计划或方向？<li>你们如何挣钱？<li>什么阻止了你们挣更多的钱？<li>公司未来一年的增长计划怎样？五年呢？<li>你们认为什么是你们的竞争优势？<li>你们的竞争优势是什么？<li>公司未来的商业规划是怎样的？有上市的计划吗？(zh)<li>都在做副业吗？</ul><h1 id=远程工作><a class=markdownIt-Anchor href=#远程工作></a> 远程工作</h1><ul><li>远程工作和办公室工作的比例是多少？<li>公司提供硬件吗？更新计划如何？<li>使用自己的硬件办公可以吗？现在有政策吗？<li>额外的附件和家具可以通过公司购买吗？这方面是否有预算？<li>有共享办公或者上网的预算吗？<li>多久需要去一次办公室？<li>公司的会议室是否一直是视频会议就绪的？</ul><h1 id=办公室布局><a class=markdownIt-Anchor href=#办公室布局></a> 办公室布局</h1><ul><li>办公室的布局如何？（开放的 / 小隔间 / 独立办公室）<li>有没有支持 / 市场 / 或者其他需要大量打电话的团队在我的团队旁边办公？</ul><h1 id=终极问题><a class=markdownIt-Anchor href=#终极问题></a> 终极问题</h1><ul><li>该职位为何会空缺？<li>公司如何保证人才不流失？<li>这份工作 / 团队 / 公司最好和最坏的方面是？<li>你最开始为什么选择了这家公司？<li>你为什么留在这家公司？</ul><h1 id=待遇><a class=markdownIt-Anchor href=#待遇></a> 待遇</h1><ul><li>如果有奖金计划的话，奖金如何分配？<li>如果有奖金计划的话，过去的几年里通常会发百分之多少的奖金？<li>有五险一金(zh)/401k(us)或者其他退休养老金等福利吗？<li>五险一金中，补充公积金一般交多少比例？/401k一般交多少比例？我可以自己选择这一比例吗？<li>有什么医疗保险吗？如果有的话何时开始？<li>有额外商业保险吗？例如人寿保险和额外的养老/医疗保险？<li>商业保险可以给家人办理吗？成年人/未成年人？<li>更换工作地点，公司付费吗？<li>是否可以申请更换工作地点？<li>是否愿意协助海外应聘者申请工作签证？</ul><h1 id=休假><a class=markdownIt-Anchor href=#休假></a> 休假</h1><ul><li>带薪休假时间有多久？<li>病假和事假是分开的还是一起算？<li>我可以提前使用假期时间吗？也就是说应休假期是负的？<li>假期的更新策略是什么样的？也就是说未休的假期能否滚入下一周期<li>照顾小孩的政策如何？<li>无薪休假政策是什么样的？<li>学术性休假政策是怎么样的？<li>孕产假政策具体是怎样的？</ul><h1 id=福利><a class=markdownIt-Anchor href=#福利></a> 福利</h1><ul><li>公司提供 mac 开发吗？<li>使用自带电脑有补贴吗？<li>公积金多少比例缴纳？<li>公司是否有食堂，是否有餐饮福利补贴？<li>是否提供租房补贴？<li>是否提供话费补贴？<li>是否有交通补贴？</ul><h1 id=人才培养><a class=markdownIt-Anchor href=#人才培养></a> 人才培养</h1><ul><li>升职加薪条件是否量化?<li>每年给团队安排多少费用用于学习培训?<li>每年组织多少次关于技术能力提升的讲座/论坛？</ul><h1 id=其他资源><a class=markdownIt-Anchor href=#其他资源></a> 其他资源</h1><p>Find more inspiration for questions in:<ul><li><span data-url="aHR0cHM6Ly93d3cuam9lbG9uc29mdHdhcmUuY29tLzIwMDAvMDgvMDkvdGhlLWpvZWwtdGVzdC0xMi1zdGVwcy10by1iZXR0ZXItY29kZS8=" class=exturl>The Joel Test: 12 Steps to Better Code<i class="fa fa-external-link-alt"></i></span> by Joel Spolsky<li><span class=exturl data-url=aHR0cHM6Ly9qdm5zLmNhL2Jsb2cvMjAxMy8xMi8zMC9xdWVzdGlvbnMtaW0tYXNraW5nLWluLWludGVydmlld3Mv>Questions I’m asking in interviews<i class="fa fa-external-link-alt"></i></span> by Julia Evans</ul><h1 id=license><a class=markdownIt-Anchor href=#license></a> License</h1><p><a href=https://creativecommons.org/licenses/by-sa/4.0/ rel=noopener target=_blank><img alt="Creative Commons License" data-src=https://i.creativecommons.org/l/by-sa/4.0/88x31.png></a><p>This work is licensed under a <span data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LXNhLzQuMC8=" class=exturl>Creative Commons Attribution-ShareAlike 4.0 International License<i class="fa fa-external-link-alt"></i></span>.</div><footer class=post-footer><div class=post-eof></div></footer></article></div><div class=post-block><article class=post-content itemscope itemtype=http://schema.org/Article><link href=https://blog.river9.top/2025/05/04/interview/%E9%97%AE%E7%AD%94%E5%B9%B3%E5%8F%B0%EF%BC%9A%E9%97%AE%E9%A2%98%E7%94%A8%E6%88%B7%E5%8C%B9%E9%85%8D%EF%BC%88%E5%A6%82%E4%BD%95%E6%89%BE%E5%88%B0%E5%90%88%E9%80%82%E7%9A%84%E4%BD%9C%E7%AD%94%E8%80%85%EF%BC%9F%EF%BC%89/ itemprop=mainEntityOfPage><span hidden itemprop=author itemscope itemtype=http://schema.org/Person> <meta content=/favicon/cirno_pat.gif itemprop=image> <meta content="River June" itemprop=name> </span><span hidden itemprop=publisher itemscope itemtype=http://schema.org/Organization> <meta content="Junetheriver's Blog" itemprop=name> <meta content="An Idiot to Anything" itemprop=description> </span><span hidden itemprop=post itemscope itemtype=http://schema.org/CreativeWork> <meta content="undefined | Junetheriver's Blog" itemprop=name> <meta itemprop=description> </span><header class=post-header><h2 itemprop="name headline" class=post-title><a class=post-title-link href=/2025/05/04/interview/%E9%97%AE%E7%AD%94%E5%B9%B3%E5%8F%B0%EF%BC%9A%E9%97%AE%E9%A2%98%E7%94%A8%E6%88%B7%E5%8C%B9%E9%85%8D%EF%BC%88%E5%A6%82%E4%BD%95%E6%89%BE%E5%88%B0%E5%90%88%E9%80%82%E7%9A%84%E4%BD%9C%E7%AD%94%E8%80%85%EF%BC%9F%EF%BC%89/ itemprop=url>问答平台：问题用户匹配（如何找到合适的作答者？）</a></h2><div class=post-meta-container><div class=post-meta><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-calendar"></i> </span> <span class=post-meta-item-text>发表于</span> <time itemprop="dateCreated datePublished" title="创建时间：2025-05-04 03:04:40 / 修改时间：11:06:55" datetime=2025-05-04T03:04:40+08:00>2025-05-04</time> </span><span class=post-meta-break></span><span class=post-meta-item title=本文字数> <span class=post-meta-item-icon> <i class="far fa-file-word"></i> </span> <span class=post-meta-item-text>本文字数：</span> <span>2.2k</span> </span><span class=post-meta-item title=阅读时长> <span class=post-meta-item-icon> <i class="far fa-clock"></i> </span> <span class=post-meta-item-text>阅读时长 ≈</span> <span>8 分钟</span> </span></div></div></header><div class=post-body itemprop=articleBody><blockquote><p>我面试的团队是想做一个类似知乎的问答类平台，然后给定一个问题，如何从微信用户或者微信公众号之类的内容产出者中找出能够回答这个问题的匹配用户？请你帮我构思一个方案</blockquote><p>这是一个 专家用户匹配 的问题，核心在于 构建用户画像 并 匹配问题和用户的兴趣/知识领域。下面是一个完整的方案，涵盖数据收集、用户建模、问题匹配以及系统优化。<p>方案：基于微信生态的问答匹配系统<ol><li>数据收集</ol><p>1.1 微信用户数据<p>可以从以下几个方面获取用户的内容偏好和专业领域：<br> • 公众号订阅情况：用户关注的公众号可以反映其兴趣领域（例如关注“Python之禅”可能是程序员）。<br> • 朋友圈/文章分享：用户经常分享的文章主题，可能表明其知识领域。<br> • 微信读书数据（若可用）：书籍阅读情况可提供更精准的用户画像。<br> • 历史问答或讨论记录（社群）：在微信群、知乎等地方发表的内容可以作为参考。<p>1.2 公众号数据<p>如果要匹配公众号的作者或内容生产者，可以抓取：<br> • 公众号文章标题 & 关键词：提取文章主题关键词，归类到不同领域。<br> • 文章正文：用 NLP 方法提取核心主题，建立索引。<br> • 作者信息：公众号运营者的背景信息（如果可得）。<br> • 互动数据：某篇文章的点赞、收藏、评论数，可以衡量作者的影响力。<ol start=2><li>用户建模</ol><p>基于数据构建用户画像，关键点在于：<br> • 用户兴趣分布：<br> • 关键词提取（TF-IDF、TextRank）<br> • 主题建模（LDA、BERT embedding 聚类）<br> • 预训练大模型嵌入（如 OpenAI Embedding、BGE）<br> • 专业领域分类：<br> • 基于百科、行业分类标准（如 ACM、GICS）<br> • 训练一个分类模型，给用户内容打标签<br> • 影响力/权威度：<br> • 互动数据（转发、点赞、收藏）<br> • 发表文章数量<br> • 被引用次数<p>💡 示例：用户 A 画像<p>领域 关键词 兴趣度<br> AI Transformer, BERT, LLM 0.8<br> 经济 股票, 投资, ETF 0.4<br> 运动 健身, 跑步 0.3<ol><li><p>问题建模<br> • 文本向量化：<br> • BERT / RoBERTa / BGE embedding<br> • TF-IDF + 主题建模（LDA）<br> • 问题分类：<br> • 训练一个多分类模型（行业分类）<br> • 规则 + 关键词匹配<br> • 难度估计：<br> • 根据问题长度、关键词专业性、历史回答情况评估（如 BM25 评分）</p><li><p>匹配算法</p></ol><p>给定一个问题 Q，如何找到合适的回答者？<p>方法 1：语义匹配<br> 1. 计算相似度<br> • 计算问题 Q 的向量 Vq<br> • 计算每个用户兴趣向量 Vu<br> • 计算 cosine_similarity(Vq, Vu)<br> 2. Top-K 召回<br> • 设定相似度阈值<br> • 排序取前 K 个用户<p>方法 2：基于内容推荐<br> 1. 基于历史回答<br> • 查找回答过相似问题的用户<br> • 计算用户对该问题的可信度（回答质量评分）<br> 2. 基于社会网络<br> • 参考微信好友/共同关注公众号<br> • 找到某个领域的“权威节点”<p>💡 示例：问题 “如何训练 BERT?”<br> • 匹配用户 A（AI 方向，匹配度 0.85）<br> • 匹配用户 B（机器学习方向，匹配度 0.78）<br> • 匹配公众号 C（深度学习专栏，匹配度 0.91）<ol start=3><li>交互与优化<br> • 反馈机制：用户可以对推荐的回答者打分，优化推荐策略<br> • 个性化推荐：结合用户的浏览/点赞习惯，调整排序<br> • 冷启动问题：使用外部数据（如知乎、论坛）预训练模型</ol><p>总结<br> 1. 数据来源：从微信订阅、公众号、朋友圈等获取用户兴趣画像<br> 2. 用户建模：构建基于文本分析的用户兴趣分布和影响力评分<br> 3. 问题建模：提取问题关键词，生成语义向量<br> 4. 匹配方法：<br> • 语义相似度（BERT embedding）<br> • 互动行为（历史回答、点赞）<br> • 社交关系（好友/关注关系）<br> 5. 优化策略：反馈系统 + 个性化排序<p>这个方案可以适用于类似知乎的问答平台，并结合微信生态的优势提升匹配精度。你觉得这个思路如何？可以根据你的需求进一步优化！ 🚀<blockquote><p>用户的问题可能很多样，可能没法预定义好问题类别，以及如何提高匹配的精度？</blockquote><p>你提到的问题很关键，涉及到 问题分类的泛化能力 和 匹配精度的提升。我们可以从无监督学习+语义匹配+用户权威度建模三方面优化：<ol><li>解决问题类别难以预定义的问题</ol><p>由于用户的问题可能很多样，预定义类别的方式可能不够泛化，因此可以采用 无监督/自监督方法 自动学习问题的类别或聚类关系。<p>1.1 无需预定义类别的方案<p>(1) 语义聚类 (Topic Modeling)<br> • 使用 BERT embedding + KMeans/HDBSCAN 对问题进行无监督聚类<br> • 结合 LDA（Latent Dirichlet Allocation） 发现潜在主题<br> • 采用 UMAP + HDBSCAN 进行高维语义降维+密度聚类，自动划分问题领域<p>💡 示例<br> • Q1：“如何微调 BERT？” -> Cluster: NLP<br> • Q2：“推荐几本深度学习的书” -> Cluster: AI 教育<br> • Q3：“ETF 和股票的区别？” -> Cluster: 投资<p>这样，即使没有事先定义类别，系统也能自动学习问题类别。<p>(2) 语义相似度检索<br> • 无分类标签匹配：直接计算 问题与用户画像的文本相似度，而不是先分类再匹配<br> • 计算新问题与历史问题的语义距离，找到相似的问题和其回答者<ol start=2><li>提高匹配精度的方法</ol><p>2.1 更精准的用户画像<p>我们需要提升用户画像的准确性，使得匹配更加精确。优化策略如下：<p>(1) 细粒度知识点提取<br> • 不是简单用 TF-IDF，而是用 Named Entity Recognition（NER）+ Dependency Parsing<br> • 例子：<br> • “如何微调 BERT？” 提取关键词 BERT, fine-tuning<br> • “ETF 和股票的区别？” 提取关键词 ETF, 股票<br> • 这样，我们能获取更精准的用户兴趣点。<p>(2) 构建用户的动态兴趣向量<br> • 用户的兴趣是动态的，而不是固定的<br> • 时间衰减：如果用户 5 年前是 Java 专家，但最近都在关注 LLM，我们应该降低 Java 权重<br> • 解决方案：<br> • 采用时间衰减权重计算兴趣向量（Exponential Decay）<br> • 或者用 RNN/Transformer 预测兴趣变化<p>(3) 结合社交关系<br> • 若用户关注某些公众号，这些公众号可能和其专业方向一致<br> • 若用户点赞、评论某些专家的文章，这些专家可能是其潜在的推荐目标<p>2.2 更精准的问题理解<p>(1) 语义增强<br> • 不仅使用单纯的文本相似度，而是结合外部知识库（如 Wikipedia, 知乎百科）进行扩展<br> • 用大模型（如 ChatGPT）进行 query expansion<br> • “如何微调 BERT？” → “BERT 微调步骤, transformer 训练, NLP 预训练模型调优”<p>(2) 关键词增强<br> • 使用 BERT + BM25，获取更相关的关键词，提高检索召回率<br> • “Transformer 训练技巧” -> 关联 “BERT, GPT, LLaMA 训练”<p>2.3 多层次匹配<p>为了提高匹配精度，我们可以结合不同层次的信息：<br> 1. 语义匹配（BERT embedding 计算相似度）<br> 2. 历史回答匹配（用户是否回答过类似问题）<br> 3. 社交网络匹配（用户是否与某些专家互动）<br> 4. 行为数据匹配（用户是否在某些领域有深度阅读/点赞）<p>最终，我们可以采用 加权融合模型，根据实验调优每个匹配策略的权重。<ol><li>结合强化学习优化匹配</ol><p>最终，我们可以用 强化学习（Reinforcement Learning, RL） 进一步优化匹配：<br> • 以用户的反馈（如点赞、采纳率）作为奖励信号<br> • 用 多臂老虎机算法（Multi-Armed Bandit, MAB）动态调整推荐策略<br> • 用 强化学习 RankNet / LambdaRank 训练一个排序模型，优化匹配顺序<p>总结<br> 1. 无需预定义问题类别<br> • 采用 BERT embedding + 聚类（HDBSCAN/UMAP） 自动发现问题类别<br> • 采用 语义相似度检索 直接匹配相似问题<br> 2. 提升匹配精度<br> • 优化用户画像（知识点提取+时间衰减）<br> • 增强问题理解（扩展查询+关键词增强）<br> • 多层次匹配（语义匹配+历史匹配+社交匹配）<br> 3. 强化学习优化<br> • 基于用户反馈 进行动态优化（采纳率、点赞数等）<p>这套方案可以大幅提升匹配的泛化能力和精度，你觉得怎么样？如果有具体的业务限制，我们可以再进一步调整方案！ 🚀</div><footer class=post-footer><div class=post-eof></div></footer></article></div><div class=post-block><article class=post-content itemscope itemtype=http://schema.org/Article><link href=https://blog.river9.top/2025/05/04/interview/GRPO/ itemprop=mainEntityOfPage><span hidden itemprop=author itemscope itemtype=http://schema.org/Person> <meta content=/favicon/cirno_pat.gif itemprop=image> <meta content="River June" itemprop=name> </span><span hidden itemprop=publisher itemscope itemtype=http://schema.org/Organization> <meta content="Junetheriver's Blog" itemprop=name> <meta content="An Idiot to Anything" itemprop=description> </span><span hidden itemprop=post itemscope itemtype=http://schema.org/CreativeWork> <meta content="undefined | Junetheriver's Blog" itemprop=name> <meta itemprop=description> </span><header class=post-header><h2 itemprop="name headline" class=post-title><a class=post-title-link href=/2025/05/04/interview/GRPO/ itemprop=url>GRPO</a></h2><div class=post-meta-container><div class=post-meta><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-calendar"></i> </span> <span class=post-meta-item-text>发表于</span> <time itemprop="dateCreated datePublished" title="创建时间：2025-05-04 03:04:40 / 修改时间：11:07:21" datetime=2025-05-04T03:04:40+08:00>2025-05-04</time> </span><span class=post-meta-break></span><span class=post-meta-item title=本文字数> <span class=post-meta-item-icon> <i class="far fa-file-word"></i> </span> <span class=post-meta-item-text>本文字数：</span> <span>4</span> </span><span class=post-meta-item title=阅读时长> <span class=post-meta-item-icon> <i class="far fa-clock"></i> </span> <span class=post-meta-item-text>阅读时长 ≈</span> <span>1 分钟</span> </span></div></div></header><div class=post-body itemprop=articleBody><p>![[Pasted image 20250430172312.png]]</div><footer class=post-footer><div class=post-eof></div></footer></article></div><nav class=pagination><span class="page-number current">1</span><a class=page-number href=/page/2/>2</a><a class="extend next" aria-label=下一页 href=/page/2/ rel=next title=下一页><i class="fa fa-angle-right"></i></a></nav></div></main><footer class=footer><div class=footer-inner><div class=copyright>© <span itemprop=copyrightYear>2025</span><span class=with-love> <i class="fa fa-9"></i> </span><span class=author itemprop=copyrightHolder>River June</span></div><div class=wordcount><span class=post-meta-item> <span class=post-meta-item-icon> <i class="fa fa-chart-line"></i> </span> <span title=站点总字数>13k</span> </span><span class=post-meta-item> <span class=post-meta-item-icon> <i class="fa fa-coffee"></i> </span> <span title=站点阅读时长>48 分钟</span> </span></div><div class=powered-by>由 <span class=exturl data-url=aHR0cHM6Ly9oZXhvLmlv>Hexo</span> & <span data-url="aHR0cHM6Ly90aGVtZS1uZXh0LmpzLm9yZw==" class=exturl>NexT.Gemini</span> 强力驱动</div></div></footer><div class="toggle sidebar-toggle" role=button><span class=toggle-line></span><span class=toggle-line></span><span class=toggle-line></span></div><div class=sidebar-dimmer></div><div aria-label=返回顶部 class=back-to-top role=button><i class="fa fa-arrow-up fa-lg"></i><span>0%</span></div><div class=reading-progress-bar></div><span aria-label="在 GitHub 上关注我" class="exturl github-corner" data-url="aHR0cHM6Ly9naXRodWIuY29tL05pY2tMZW5ub25MaXU=" title="在 GitHub 上关注我"><svg viewbox="0 0 250 250" aria-hidden=true height=80 width=80><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" style="transform-origin: 130px 106px;" class=octo-arm fill=currentColor></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" class=octo-body fill=currentColor></path></svg></span><noscript><div class=noscript-warning>Theme NexT works best with JavaScript enabled</div></noscript><script class=next-config data-name=disqus type=application/json>{"enable":true,"shortname":"blog-river9","count":false,"i18n":{"disqus":"disqus"}}</script><script defer src=/js/third-party/comments/disqus.js></script>